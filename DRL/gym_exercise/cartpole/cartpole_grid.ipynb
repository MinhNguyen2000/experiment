{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177b3eb5",
   "metadata": {},
   "source": [
    "# DQN Grid Search\n",
    "\n",
    "This script is an extension to the inverted pendulum DQN algorithm in inv_pend.ipynb. This scripts automates the grid search in a hyperparameter space to explore the best performance of DQN.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5928a33",
   "metadata": {},
   "source": [
    "TODO\n",
    "- [ ] Package functions related to the experiment in a `GridSearch` class\n",
    "    - **Attributes:**\n",
    "        - Hyperparameters - model arch, lr , buffer_size, min_replay_szie, target_update_freq, gamma, eps_start, eps_end, eps_decay, episode_train, and batch_size\n",
    "        - The simulation environment\n",
    "    - **Methods:** \n",
    "        - `create_directory()` - for storing the training results for each hyperparameter configuration\n",
    "        - `eps_greedy_policy()` - for picking out an action given the observation\n",
    "        - `DQN_train()` - for training a Q network from simulation\n",
    "\n",
    "- [ ] Save the model (parameters and architecture) following training in the grid searchd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                       # To draw a random batch of samples form the replay buffer\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os                                               # For saving models and training results\n",
    "from datetime import datetime                           # For creating the directory of each training run\n",
    "import json                                             # For storing training parameters during each run\n",
    "import re                                               # For checking the latest trial #\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from collections import deque       # replay buffer is a double ended queue that allows elements to be added either to the end or the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ab4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc95fe8",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet_MLP(nn.Module):\n",
    "    ''' A QNetwork class that dynamically initialize an MLP Q Net'''\n",
    "    def __init__(self,input_dim,output_dim,hidden_layer = [64,32]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for size in hidden_layer:\n",
    "            self.layers.append(nn.Linear(self.input_dim, size))\n",
    "            self.input_dim = size\n",
    "        \n",
    "        self.layers.append(nn.Linear(self.input_dim,self.output_dim))\n",
    "\n",
    "        self.cuda()\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input_data = torch.relu(layer(input_data))\n",
    "        return self.layers[-1](input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aa2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(model_id: int,\n",
    "                     lr: float, \n",
    "                     gamma: float,\n",
    "                     epsilon_decay: int,\n",
    "                     batch_size: int, \n",
    "                     buffer_size: int,\n",
    "                     target_update_freq: int):\n",
    "    ''' Function that creates directory to save model state_dict, architecture, training configuration, and history\n",
    "\n",
    "    Parameters: \n",
    "    ------------\n",
    "    (hyperparameters for differentiating between different directory)\n",
    "    \n",
    "    lr : float\n",
    "        the learning rate to optimize the Q network\n",
    "    gamma : float \n",
    "        the discount rate in Q learning\n",
    "    epsilon_decay : integer\n",
    "        the amount of episode over which the exploratory rate (epsilon) decays\n",
    "    batch_size : integer\n",
    "        number of experience drawn from replay buffer to train the behaviour network\n",
    "    buffer_size : integer\n",
    "        the number of samples in the replay buffer at a time\n",
    "    target_udpate_freq : integer\n",
    "        the amount of step count during the training process before updating the target Q net (loading the parameters of the behaviour net onto the target Q Net)\n",
    "    \n",
    "\n",
    "    Returns\n",
    "    ------------\n",
    "    name_codified : str\n",
    "        the shortened name for the current experiment \n",
    "    hyperparameters_codified : str\n",
    "        the shortened string of hyperparameter configuration\n",
    "    OUTPUT_DIR : path\n",
    "        the directory to which the training results and model (state_dict and architecture) will be saved\n",
    "    '''\n",
    "    timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "    BASE_DIR = os.getcwd()\n",
    "    RESULT_DIR = os.path.join(BASE_DIR,\"cartpole_DQN_results\")\n",
    "    os.makedirs(RESULT_DIR, exist_ok=True)      # Create the directory if one does not already exist\n",
    "\n",
    "    # Find the trial # of the latest run\n",
    "    existing_runs = [d for d in os.listdir(RESULT_DIR) if os.path.isdir(os.path.join(RESULT_DIR,d))]\n",
    "    run_numbers = [int(re.search(r'run_(\\d{5})',d).group(1)) for d in existing_runs if re.match(r'run_\\d{5}',d)]\n",
    "    trial_number = max(run_numbers,default=-1)+1\n",
    "\n",
    "    # Create a folder for the run\n",
    "    name_codified = f\"run_{trial_number:05d}\"\n",
    "    OUTPUT_DIR = os.path.join(RESULT_DIR,name_codified)\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)      # Create the directory\n",
    "\n",
    "    \n",
    "    # Store the training configs in JSON file\n",
    "    training_params = {\n",
    "        'model_id': model_id,\n",
    "        'lr': lr,\n",
    "        'gamma': gamma,\n",
    "        'epsilon_decay': epsilon_decay,\n",
    "        'batch_size': batch_size,\n",
    "        'buffer_size': buffer_size,\n",
    "        'target_update_freq': target_update_freq\n",
    "    }\n",
    "\n",
    "    # Append the mapping from run # to hyperparameter configuration in a JSON file inside RESULT_DIR\n",
    "    trial_to_param_path = os.path.join(RESULT_DIR,'trial_to_param.json')\n",
    "    if os.path.exists(trial_to_param_path):\n",
    "        with open(trial_to_param_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        data = {name_codified: []}\n",
    "\n",
    "    hyperparam_codified = f\"{model_id}_{lr}_{buffer_size}_{target_update_freq}_{gamma}_{epsilon_decay}_{batch_size}\"\n",
    "    hyperparam_codified_time = f\"{timestamp}_{model_id}_{lr}_{buffer_size}_{target_update_freq}_{gamma}_{epsilon_decay}_{batch_size}\"\n",
    "    data[name_codified] = hyperparam_codified_time\n",
    "\n",
    "    with open(trial_to_param_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "    # Store training parameters in each run \n",
    "    param_path = os.path.join(OUTPUT_DIR, \"param_config.json\")\n",
    "    with open(param_path, \"w\") as f:\n",
    "        json.dump({\"parameters\": training_params}, f, indent=2)\n",
    "\n",
    "    return name_codified, hyperparam_codified, OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy_policy(env, obs, epsilon: float, q_network: QNet_MLP):\n",
    "    ''' Function to take an action according to an epsilon-greedy policy and a Q-network'''\n",
    "    if np.random.random() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.tensor(obs, dtype=torch.float32, device = 'cuda').unsqueeze(0)\n",
    "            q_values = q_network(state_tensor)\n",
    "            action = q_values.argmax().item()\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_eval(env_test, q_network, n_episode_test = 500):\n",
    "    ''' Assess the average reward when following a q_network in a test environment with random state initialization '''\n",
    "    \n",
    "    total_reward = 0\n",
    "    for i in range(n_episode_test):\n",
    "        obs,_ = env_test.reset()\n",
    "        done = False\n",
    "        eps_reward = 0\n",
    "\n",
    "        while not done:                 # Step thorugh the episode\n",
    "            action = eps_greedy_policy(env_test, obs, epsilon=0, q_network=q_network)\n",
    "            next_obs, reward, term, trunc, _ = env_test.step(action)\n",
    "\n",
    "            eps_reward += reward\n",
    "\n",
    "            obs = next_obs\n",
    "            done = term or trunc\n",
    "    \n",
    "        total_reward += eps_reward\n",
    "    average_reward = total_reward / n_episode_test\n",
    "\n",
    "    return average_reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086ecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(q_network: nn.Module, optimizer: torch.optim.Optimizer, save_path):\n",
    "    ''' Function to save the model and optimizer state_dict for inference or continued training '''\n",
    "    torch.save({\n",
    "        'model_state_dict': q_network.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }, os.path.join(save_path, 'q_network_checkpoint.pth'))\n",
    "\n",
    "def load_model(q_network: nn.Module, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    q_network.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN_train(env: gym.Env, env_test: gym.Env,\n",
    "              q_network: nn.Module, target_net: nn.Module, optimizer: torch.optim.Optimizer, \n",
    "              replay_buffer,\n",
    "              target_update_freq,\n",
    "              gamma,\n",
    "              eps_start, eps_end, eps_decay,\n",
    "              episode_train,\n",
    "              batch_size, \n",
    "              save_path,\n",
    "              seed = 42):\n",
    "    ''' Function to train a policy for a set of hyperparameters '''\n",
    "\n",
    "    msg = \"Training ended, no good model found!\"\n",
    "\n",
    "    reward_history = np.zeros(episode_train)\n",
    "    epsilon = eps_start\n",
    "    step_count = 0\n",
    "    episode = 0\n",
    "    target_network_update_count = 0\n",
    "\n",
    "    # Control of early stopping\n",
    "    consecutive_pass_count = 0           # Number of consecutive episodes where performance exceeds a threshold\n",
    "    CONSECUTIVE_PASS_LIMIT = 3          # No. of consecutive episodes with higher performance than reward limit\n",
    "    EPISODE_REWARD_LIMIT = 450\n",
    "    best_reward = 0\n",
    "    performance_crit = False\n",
    "    train_terminated = False\n",
    "    val_history = {}                    # Monitor which episode had a validation run, the train reward, and the validation (test) reward \n",
    "\n",
    "    while not train_terminated:     # Experiment level - loop through episodes\n",
    "        obs, _ = env.reset(seed=seed)\n",
    "        eps_rewards = 0\n",
    "    \n",
    "        while True:                 # Episode level - loop through steps\n",
    "            action = eps_greedy_policy(env, obs, epsilon, q_network)\n",
    "\n",
    "            # Interact with the environment\n",
    "            next_obs, reward, term, trunc, _ = env.step(action)\n",
    "            done = term or trunc\n",
    "            replay_buffer.append((obs, action, reward, next_obs, done))\n",
    "            obs = next_obs\n",
    "            eps_rewards += reward\n",
    "            step_count += 1\n",
    "\n",
    "            # Train the Q-net using a batch of samples from the experience replay\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                batch = random.sample(replay_buffer, batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "                states =        torch.tensor(np.array(states),      dtype = torch.float32,  device='cuda')           # Shape of (BATCH_SIZE, 4). Data structure of [[p1 v1 theta1 dtheta1], [p2 v2 theta2 dtheta2], ...]\n",
    "                actions =       torch.tensor(actions,               dtype = torch.long,     device='cuda').unsqueeze(1)        # Must unsqueeze to have shape (BATCH_SIZE, 1). From [a1, a2, ...] to [[a1], [a2], ... [a_BATCH_SIZE]]\n",
    "                rewards =       torch.tensor(rewards,               dtype = torch.float32,  device='cuda').unsqueeze(1)\n",
    "                next_states =   torch.tensor(np.array(next_states), dtype = torch.float32,  device = 'cuda')\n",
    "                dones =         torch.tensor(dones,                 dtype = torch.float32,  device='cuda').unsqueeze(1)\n",
    "                \n",
    "                # Compute targets using target network Q(s',a',w_i^-)\n",
    "                with torch.no_grad():\n",
    "                    target_q_values = target_net(next_states)       # Find a batch of Q(s',a',w_i^-) from the batch of next_states\n",
    "                    max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "                    targets = rewards + gamma * max_target_q_values * (1 - dones)       # (1-dones) to avoid over estimating the value of terminal states. The target should only be the reward in the terminal states\n",
    "            \n",
    "                # Compute the current Q values for the actions taken Q(s,a,w_i)\n",
    "                q_values = q_network(states).gather(1, actions)         # obtain the q_values associated to the actual action taken in each sample\n",
    "\n",
    "                # Update the parameters of the behaviour q_network\n",
    "                loss = nn.MSELoss()(q_values, targets)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Periodically update the target network by loading the weights from the behavior network\n",
    "            if step_count % target_update_freq == 0:\n",
    "                target_network_update_count += 1\n",
    "                target_net.load_state_dict(q_network.state_dict())\n",
    "\n",
    "            if done:        # End of a training episode\n",
    "                break\n",
    "\n",
    "        # Decay epsilon after an episode\n",
    "        epsilon = max(eps_end, epsilon - (eps_start - eps_end)/eps_decay)\n",
    "\n",
    "        reward_history[episode] = eps_rewards\n",
    "        # print(f\"Episode {episode:5d}: Total reward = {eps_rewards:5.1f}, Epsilon = {epsilon:.3f}, Step count = {step_count:5d}, Target update count = {target_network_update_count:3d}\")\n",
    "        # print(f\"Average reward {sum(reward_history[:episode])/(episode+1):.2f}\")\n",
    "\n",
    "        \n",
    "        if episode % 10 == 0:                   # print progress periodically\n",
    "            print(f\"Episode {episode:5d}: Total reward = {eps_rewards:5.1f}, Epsilon = {epsilon:.3f}\", end = \"\\r\")\n",
    "\n",
    "        # Early stopping condition\n",
    "        if eps_rewards >= EPISODE_REWARD_LIMIT:\n",
    "            test_reward = policy_eval(env_test, q_network, 100)\n",
    "            val_history[episode] = [eps_rewards, test_reward]\n",
    "\n",
    "            if test_reward >= best_reward:           # Set the new best reward\n",
    "                best_reward = test_reward\n",
    "                save_model(q_network, optimizer, save_path)\n",
    "                msg = f\"Training terminated due to episode limit, best model saved at episode {episode:5d}\"\n",
    "            if test_reward > EPISODE_REWARD_LIMIT: \n",
    "                consecutive_pass_count += 1\n",
    "            else: consecutive_pass_count = 0\n",
    "        else:\n",
    "            consecutive_pass_count = 0\n",
    "            \n",
    "        # Performance criteria - if good results for several episodes => training performance satisfied and terminate early\n",
    "        if consecutive_pass_count >= CONSECUTIVE_PASS_LIMIT:\n",
    "            performance_crit = True \n",
    "            msg = f\"Early termination at episode {episode:5d}, desired performance reached\"\n",
    "\n",
    "\n",
    "        episode += 1\n",
    "\n",
    "        # Checking for early training termination or truncation\n",
    "        train_terminated = (episode >= episode_train) or (performance_crit)\n",
    "    print(\"\\n\")\n",
    "    return reward_history, val_history, msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for EMA filters and plotting data\n",
    "def EMA_filter(reward: list, alpha):\n",
    "    ''' Function that runs an exponential moving average filter along a datastream '''\n",
    "    output = np.zeros(len(reward)+1)\n",
    "    output[0] = reward[0]\n",
    "    for idx, item in enumerate(reward):\n",
    "        output[idx+1] = (1 - alpha) * output[idx] + alpha * item\n",
    "    \n",
    "    return output\n",
    "\n",
    "def plot_reward_hist(reward_history: list, hyperparam_config: str, save_path = None, alpha = 0.1):\n",
    "    ''' Function that plots the reward and filtered reward per episode, then saves the plot in a specified save directory'''\n",
    "    n_episodes= len(reward_history)\n",
    "    episodes = range(n_episodes)\n",
    "    filtered_reward_hist = EMA_filter(reward_history, alpha)\n",
    "\n",
    "    plt.figure(figsize=(20,6))\n",
    "    plt.plot(episodes, reward_history[:n_episodes], color = \"blue\")\n",
    "    plt.plot(episodes, filtered_reward_hist[:n_episodes], color = \"red\")\n",
    "    plt.title(f'Total reward per episode - {hyperparam_config}')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.legend(['Total reward','Filtered reward'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(os.path.join(save_path,'reward_history.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script test --no-raise-error\n",
    "# Test creating the Q network with dynamic hidden layer when specifying the list of hidden nodes\n",
    "\n",
    "Q_net = QNet_MLP(obs_space,action_space,[64,32])\n",
    "summary(Q_net, (obs_space,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a80f799",
   "metadata": {},
   "source": [
    "## Parameter Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d83409",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = {\n",
    "    'DQN_MLP_v0': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [64,32]\n",
    "    },\n",
    "    'DQN_MLP_v1': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [32,32]\n",
    "    },\n",
    "    'DQN_MLP_v2': {\n",
    "        \n",
    "        'class': QNet_MLP,\n",
    "        'config': [32,16]\n",
    "    },\n",
    "    'DQN_MLP_v3': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [16,16]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e314f87",
   "metadata": {},
   "source": [
    "The block below is used for testing the model creation automation (Uncomment the first line to run the test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43edbf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script test --no-raise-error\n",
    "for model in model_registry:\n",
    "    Q_net = QNet_MLP(obs_space, action_space, model_registry[model]['config'])\n",
    "    # print(model_registry[model]['config'])\n",
    "    print(Q_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060fc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual parameter grid\n",
    "param_grid = {\n",
    "    'MODEL': [model for model in model_registry],\n",
    "    'LR': [5e-4, 1e-3, 5e-3, 1e-2],\n",
    "    \"BUFFER_SIZE\": [1000, 5000, 10000],\n",
    "    \"MIN_REPLAY_SIZE\": [1000],\n",
    "    \"TARGET_UPDATE_FREQ\": [1000, 5000, 10000],\n",
    "\n",
    "    \"GAMMA\": [0.90, 0.95, 0.98],\n",
    "    \"EPSILON_START\": [1.0],\n",
    "    \"EPSILON_END\": [0.1],\n",
    "    \"EPSILON_DECAY\": [1000, 5000, 10000],\n",
    "\n",
    "    \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "    \"BATCH_SIZE\": [32, 64, 128]\n",
    "}\n",
    "\n",
    "success_criteria = 450                      #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam grid - vary one at a time\n",
    "param_grid = {\n",
    "    'MODEL': ['DQN_MLP_v0'],\n",
    "    'LR': [5e-4],\n",
    "    \"BUFFER_SIZE\": [5000],\n",
    "    \"MIN_REPLAY_SIZE\": [1000],\n",
    "    \"TARGET_UPDATE_FREQ\": [1000],\n",
    "\n",
    "    \"GAMMA\": [0.90, 0.95, 0.98],\n",
    "    \"EPSILON_START\": [1.0],\n",
    "    \"EPSILON_END\": [0.1],\n",
    "    \"EPSILON_DECAY\": [5000],\n",
    "\n",
    "    \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "    \"BATCH_SIZE\": [32]\n",
    "}\n",
    "\n",
    "success_criteria = 450                      #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c535ea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simplified param grid to test functionality\n",
    "# param_grid = {\n",
    "#     # 'MODEL': [model for model in model_registry],\n",
    "#     'MODEL': ['DQN_MLP_v0'],\n",
    "#     'LR': [5e-4],\n",
    "#     \"BUFFER_SIZE\": [5000],\n",
    "#     \"MIN_REPLAY_SIZE\": [1000],\n",
    "#     \"TARGET_UPDATE_FREQ\": [1000],\n",
    "\n",
    "#     \"GAMMA\": [0.95],\n",
    "#     \"EPSILON_START\": [1.0],\n",
    "#     \"EPSILON_END\": [0.1],\n",
    "#     \"EPSILON_DECAY\": [5000],\n",
    "\n",
    "#     \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "#     \"BATCH_SIZE\": [32]\n",
    "# }\n",
    "\n",
    "# success_criteria = 450                      #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb6584",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da69956",
   "metadata": {},
   "source": [
    "Using itertools to loop through each combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "keys, values = zip(*param_grid.items())\n",
    "# keys, values = param_grid.keys(), param_grid.values()\n",
    "num_config = len(list(itertools.product(*values)))\n",
    "\n",
    "# Set fixed seed\n",
    "seed = 42\n",
    "np.random.seed(seed); random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "for idx, v in enumerate(itertools.product(*values)):\n",
    "\n",
    "    # Unpacking the hyperparameter configurations\n",
    "    config = dict(zip(keys,v))\n",
    "    MODEL_NAME = config['MODEL']\n",
    "    MODEL_CLASS = model_registry[MODEL_NAME]['class']\n",
    "    MODEL_CONFIG = model_registry[MODEL_NAME]['config']\n",
    "    match = re.search(r'v\\d+',MODEL_NAME)\n",
    "    MODEL_ID = match.group(0) if match else 404\n",
    "\n",
    "    LR = config['LR']\n",
    "    BUFFER_SIZE = config['BUFFER_SIZE']\n",
    "    MIN_REPLAY_SIZE = config['MIN_REPLAY_SIZE']\n",
    "    TARGET_UPDATE_FREQ = config['TARGET_UPDATE_FREQ']\n",
    "    GAMMA = config['GAMMA']\n",
    "    EPS_START = config['EPSILON_START']\n",
    "    EPS_END = config['EPSILON_END']\n",
    "    EPS_DECAY = config['EPSILON_DECAY']\n",
    "    EPISODE_TRAIN = config['EPISODE_TRAIN']\n",
    "    BATCH_SIZE = config['BATCH_SIZE']\n",
    "\n",
    "\n",
    "    # Re-initialize the environment\n",
    "    env = gym.make('CartPole-v1')\n",
    "    env_test = gym.make('CartPole-v1')\n",
    "    obs,_ = env.reset(seed=seed)\n",
    "\n",
    "    obs_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "\n",
    "\n",
    "    # Re-initialize the NN models\n",
    "    Q_net = MODEL_CLASS(obs_space,action_space,MODEL_CONFIG)\n",
    "    target_net = MODEL_CLASS(obs_space,action_space,MODEL_CONFIG)\n",
    "    target_net.load_state_dict(Q_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.SGD(Q_net.parameters(), lr = LR)\n",
    "    # optimizer = optim.Adam(Q_net.parameters(), lr = LR)\n",
    "\n",
    "    # Re-initialize and pre-fill the replay buffer\n",
    "    replay_buffer = deque(maxlen = BUFFER_SIZE)\n",
    "    \n",
    "    obs, _ = env.reset()\n",
    "    for _ in range(MIN_REPLAY_SIZE):\n",
    "        action = env.action_space.sample()\n",
    "        next_obs, reward, term, trunc, _ = env.step(action)\n",
    "        done = term or trunc\n",
    "\n",
    "        replay_buffer.append((obs, action, reward, next_obs, done))\n",
    "        obs = next_obs if not done else env.reset()[0]\n",
    "\n",
    "    # Create the directory to store results\n",
    "    _, hyperparam_config, save_path = create_directory(MODEL_ID,LR,GAMMA,EPS_DECAY,BATCH_SIZE,BUFFER_SIZE,TARGET_UPDATE_FREQ)\n",
    "\n",
    "    # Training information\n",
    "    print(f'Trial {idx+1}/{num_config} - model {MODEL_NAME}, lr={LR}, buffer={BUFFER_SIZE}, target_freq={TARGET_UPDATE_FREQ}, gamma={GAMMA}, eps_decay={EPS_DECAY}, batch_size={BATCH_SIZE}')\n",
    "    \n",
    "    # Train the DQN with the given hyperparameter configuration\n",
    "    start_time = time.time()\n",
    "    reward_history, val_history, msg = DQN_train(env, env_test,\n",
    "                                    Q_net, target_net,optimizer,\n",
    "                                    replay_buffer,\n",
    "                                    TARGET_UPDATE_FREQ, GAMMA, \n",
    "                                    EPS_START, EPS_END, EPS_DECAY,\n",
    "                                    EPISODE_TRAIN,\n",
    "                                    BATCH_SIZE, \n",
    "                                    save_path,\n",
    "                                    seed=seed)\n",
    "    end_time = time.time()\n",
    "    print(f\"Runtime - {end_time - start_time:.3f}\")\n",
    "    print(msg)\n",
    "\n",
    "    # Load the best Q net parameter from the experiment\n",
    "    model_path = os.path.join(save_path,'q _network_checkpoint.pth')\n",
    "    load_model(Q_net, model_path)\n",
    "\n",
    "    # Average test reward of the resulting policy\n",
    "    env_test = gym.make('CartPole-v1')\n",
    "    average_reward = policy_eval(env_test, Q_net, n_episode_test=500)\n",
    "    print(f\"Validation average reward {average_reward:4.2f}\")\n",
    "\n",
    "    # Store the validation hisotry and average test reward in the param_config JSON file\n",
    "    param_path = os.path.join(save_path,'param_config.json')\n",
    "    if os.path.exists(param_path):\n",
    "        with open(param_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        data = {}\n",
    "    data['val_history'] = val_history\n",
    "    data['test_result'] = average_reward\n",
    "    \n",
    "    \n",
    "\n",
    "    with open(param_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    # Display and save the reward history in current trial folderr \n",
    "    plot_reward_hist(reward_history, hyperparam_config, save_path)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def4e72",
   "metadata": {},
   "source": [
    "## Load and Simulate Saved Model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22994a",
   "metadata": {},
   "source": [
    "# Double DQN (DDQN) Grid Search\n",
    "\n",
    "This script is an extension to the inverted pendulum DQN algorithm in inv_pend.ipynb. This scripts automates the grid search in a hyperparameter space to explore the best performance of DQN.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d86e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                       # To draw a random batch of samples form the replay buffer\n",
    "import gymnasium as gym             # To create the inverted pendulum environment\n",
    "import torch                        \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import deque       # replay buffer is a double ended queue that allows elements to be added either to the end or the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af745b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e2e58",
   "metadata": {},
   "source": [
    "## Parameter & Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735f4e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Actual parameter grid\n",
    "# param_grid = {\n",
    "#     'MODEL': [model for model in model_registry],\n",
    "#     'LR': [5e-4, 1e-3, 5e-3, 1e-2],\n",
    "#     \"BUFFER_SIZE\": [1000, 5000, 10000],\n",
    "#     \"MIN_REPLAY_SIZE\": [1000],\n",
    "#     \"TARGET_UPDATE_FREQ\": [1000, 5000, 10000],\n",
    "\n",
    "#     \"GAMMA\": [0.90, 0.95, 0.98],\n",
    "#     \"EPSILON_START\": [1.0],\n",
    "#     \"EPSILON_END\": [0.1],\n",
    "#     \"EPSILON_DECAY\": [1000, 5000, 10000],\n",
    "\n",
    "#     \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "#     \"BATCH_SIZE\": [32, 64, 128]\n",
    "# }\n",
    "\n",
    "# success_criteria = 450                      #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe39380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam grid - vary one at a time\n",
    "param_grid = {\n",
    "    'MODEL': ['DQN_MLP_v0'],\n",
    "    'LR': [1e-4, 5e-4, 1e-3, 5e-3],\n",
    "    # 'LR': [1e-4],\n",
    "    \"BUFFER_SIZE\": [5000],\n",
    "    \"MIN_REPLAY_SIZE\": [1000],\n",
    "    \"TARGET_UPDATE_FREQ\": [1000],\n",
    "\n",
    "    \"GAMMA\": [0.95],\n",
    "    \"EPSILON_START\": [1.0],\n",
    "    \"EPSILON_END\": [0.1],\n",
    "    \"EPSILON_DECAY\": [5000],\n",
    "\n",
    "    \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "    \"BATCH_SIZE\": [32]\n",
    "}\n",
    "\n",
    "CUDA_ENABLED = False                        # Control whether to use cuda or not\n",
    "SUCCESS_CRITERIA = 450                      # Control the performance threshold for early stopping during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a1e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simplified param grid to test functionality\n",
    "# param_grid = {\n",
    "#     # 'MODEL': [model for model in model_registry],\n",
    "#     'MODEL': ['DQN_MLP_v0'],\n",
    "#     'LR': [5e-4],\n",
    "#     \"BUFFER_SIZE\": [5000],\n",
    "#     \"MIN_REPLAY_SIZE\": [1000],\n",
    "#     \"TARGET_UPDATE_FREQ\": [1000],\n",
    "\n",
    "#     \"GAMMA\": [0.95],\n",
    "#     \"EPSILON_START\": [1.0],\n",
    "#     \"EPSILON_END\": [0.1],\n",
    "#     \"EPSILON_DECAY\": [5000],\n",
    "\n",
    "#     \"EPISODE_TRAIN\": [5000],                # training truncation criteria\n",
    "#     \"BATCH_SIZE\": [32]\n",
    "# }\n",
    "\n",
    "# success_criteria = 450                      #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet_MLP(nn.Module):\n",
    "    ''' A QNetwork class that dynamically initialize an MLP Q Net'''\n",
    "    def __init__(self,input_dim,output_dim,hidden_layer = [64,32], cuda_enabled=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for size in hidden_layer:\n",
    "            self.layers.append(nn.Linear(self.input_dim, size))\n",
    "            self.input_dim = size\n",
    "        \n",
    "        self.layers.append(nn.Linear(self.input_dim,self.output_dim))\n",
    "\n",
    "        if cuda_enabled: self.cuda()\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input_data = torch.relu(layer(input_data))\n",
    "        return self.layers[-1](input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb8f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = {\n",
    "    'DQN_MLP_v0': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [64,32]\n",
    "    },\n",
    "    'DQN_MLP_v1': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [32,32]\n",
    "    },\n",
    "    'DQN_MLP_v2': {\n",
    "        \n",
    "        'class': QNet_MLP,\n",
    "        'config': [32,16]\n",
    "    },\n",
    "    'DQN_MLP_v3': {\n",
    "        'class': QNet_MLP,\n",
    "        'config': [16,16]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76cf7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN_experiment():\n",
    "    def __init__(self, model_name: str,      # \"DQN_MLP_v0\" or \"DQN_MLP_v1\"\n",
    "                 model_registry, \n",
    "                 lr: float, \n",
    "                 buffer_size: int, \n",
    "                 target_update_freq: int, \n",
    "                 gamma: float, \n",
    "                 eps_start: float, \n",
    "                 eps_decay: int,\n",
    "                 eps_end: float, \n",
    "                 batch_size: int,\n",
    "                 seed = 42,\n",
    "                 cuda_enabled = False):\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.cuda_enabled = cuda_enabled\n",
    "        \n",
    "        ''' Defining hyperparameters in the experiment '''\n",
    "        self.model_name = model_name                                        # Full name of the model\n",
    "        self.model_class = model_registry[self.model_name]['class']             # The model class \"QNet_MLP\" or \"QNet_test\"\n",
    "        self.model_config = model_registry[self.model_name]['config']       # List of nodes in each hidden layer\n",
    "        match = re.search(r'v\\d+',self.model_name)\n",
    "        self.model_id = match.group(0) if match else 404                    # Extract the \"v0\" or \"v1\" out of model name for abbreviation\n",
    "\n",
    "        # Hyperparameters of the experiment\n",
    "        self.lr = lr\n",
    "        self.buffer_size = buffer_size\n",
    "        self.target_update_freq = target_update_freq\n",
    "        self.gamma = gamma\n",
    "        self.eps_start, self.eps, self.eps_decay, self.eps_end = eps_start, eps_start, eps_decay, eps_end\n",
    "        self.batch_size = batch_size\n",
    "        self.episode_train = 5000\n",
    "        self.min_replay_size = 1000\n",
    "\n",
    "        # Initialize the train and validation environments\n",
    "        self.env = gym.make(\"CartPole-v1\")\n",
    "        self.env_val = gym.make(\"CartPole-v1\")\n",
    "        self.obs_space = self.env.observation_space.shape[0]\n",
    "        self.act_space = self.env.action_space.n\n",
    "\n",
    "        # Initialize the 2 Q networks and the optimizer for the behavior Q_net\n",
    "        self.Q_net = self.model_class(self.obs_space, self.act_space, self.model_config)\n",
    "        self.target_net = self.model_class(self.obs_space, self.act_space, self.model_config)\n",
    "        self.target_net.load_state_dict(self.Q_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "        self.optimizer = optim.SGD(self.Q_net.parameters(), lr = self.lr)\n",
    "\n",
    "        self.save_path = \"\"                                             # Directory of the current run\n",
    "        self.model_path = \"\"                                            # Path to a model \n",
    "        self.hyperparam_config = \"\"                                     # Shortened list of importatnt hyperparameters\n",
    "        self.reward_history = np.zeros(self.episode_train)\n",
    "        self.val_history = {}                                           # Monitor which episode had a validation run, the train reward, and the validation (test) reward \n",
    "\n",
    "    def create_directory(self):\n",
    "        ''' Function that creates directory to save model state_dict, architecture, training configuration, and history\n",
    "\n",
    "        Parameters: \n",
    "        ------------\n",
    "        (hyperparameters for differentiating between different directory)\n",
    "        \n",
    "        lr : float\n",
    "            the learning rate to optimize the Q network\n",
    "        gamma : float \n",
    "            the discount rate in Q learning\n",
    "        epsilon_decay : integer\n",
    "            the amount of episode over which the exploratory rate (epsilon) decays\n",
    "        batch_size : integer\n",
    "            number of experience drawn from replay buffer to train the behaviour network\n",
    "        buffer_size : integer\n",
    "            the number of samples in the replay buffer at a time\n",
    "        target_udpate_freq : integer\n",
    "            the amount of step count during the training process before updating the target Q net (loading the parameters of the behaviour net onto the target Q Net)\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        ------------\n",
    "        name_codified : str\n",
    "            the shortened name for the current experiment \n",
    "        hyperparameters_codified : str\n",
    "            the shortened string of hyperparameter configuration\n",
    "        OUTPUT_DIR : path\n",
    "            the directory to which the training results and model (state_dict and architecture) will be saved\n",
    "        '''\n",
    "        timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "        BASE_DIR = os.getcwd()\n",
    "        RESULT_DIR = os.path.join(BASE_DIR, \"cartpole_DDQN_results\")\n",
    "        os.makedirs(RESULT_DIR, exist_ok=True)      # Create the directory if one does not already exist\n",
    "\n",
    "        # Find the trial # of the latest run\n",
    "        existing_runs = [d for d in os.listdir(RESULT_DIR) if os.path.isdir(os.path.join(RESULT_DIR,d))]\n",
    "        run_numbers = [int(re.search(r'run_(\\d{5})',d).group(1)) for d in existing_runs if re.match(r'run_\\d{5}',d)]\n",
    "        trial_number = max(run_numbers,default=-1)+1\n",
    "\n",
    "        # Create a folder for the run\n",
    "        name_codified = f\"run_{trial_number:05d}\"\n",
    "        OUTPUT_DIR = os.path.join(RESULT_DIR,name_codified)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)      # Create the directory\n",
    "\n",
    "        # Append the mapping from run # to hyperparameter configuration in a JSON file inside RESULT_DIR\n",
    "        trial_to_param_path = os.path.join(RESULT_DIR,'trial_to_param.json')\n",
    "        if os.path.exists(trial_to_param_path):\n",
    "            with open(trial_to_param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {name_codified: []}\n",
    "\n",
    "        if self.cuda_enabled:\n",
    "            hyperparam_codified = f\"DDQN_OOP_CUDA_{self.model_id}_{self.lr}_{self.buffer_size}_{self.target_update_freq}_{self.gamma}_{self.eps_decay}_{self.batch_size}\"\n",
    "            hyperparam_codified_time = f\"{timestamp}_DDQN_OOP_CUDA_{self.model_id}_{self.lr}_{self.buffer_size}_{self.target_update_freq}_{self.gamma}_{self.eps_decay}_{self.batch_size}\"\n",
    "        else:   \n",
    "            hyperparam_codified = f\"DDQN_OOP_nCUDA_{self.model_id}_{self.lr}_{self.buffer_size}_{self.target_update_freq}_{self.gamma}_{self.eps_decay}_{self.batch_size}\"\n",
    "            hyperparam_codified_time = f\"{timestamp}_DDQN_OOP_nCUDA_{self.model_id}_{self.lr}_{self.buffer_size}_{self.target_update_freq}_{self.gamma}_{self.eps_decay}_{self.batch_size}\"\n",
    "        data[name_codified] = hyperparam_codified_time\n",
    "\n",
    "        with open(trial_to_param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Store the training configs in JSON file\n",
    "        training_params = {\n",
    "            'OOP':                  True,\n",
    "            'CUDA':                 self.cuda_enabled,\n",
    "            'model_id':             self.model_id,\n",
    "            'lr':                   self.lr,\n",
    "            'gamma':                self.gamma,\n",
    "            'epsilon_decay':        self.eps_decay,\n",
    "            'batch_size':           self.batch_size,\n",
    "            'buffer_size':          self.buffer_size,\n",
    "            'target_update_freq':   self.target_update_freq\n",
    "        }\n",
    "\n",
    "        # Store training parameters in each run \n",
    "        param_path = os.path.join(OUTPUT_DIR, \"param_config.json\")\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump({\"parameters\": training_params}, f, indent=2)\n",
    "\n",
    "        return name_codified, hyperparam_codified, OUTPUT_DIR\n",
    "    \n",
    "    def eps_greedy_policy(self, env, obs, epsilon):      \n",
    "        ''' Function to take an action according to an epsilon-greedy policy and a Q-network \n",
    "        \n",
    "        Parameters:\n",
    "        ------------\n",
    "\n",
    "        env : gym.Env\n",
    "            the environment that the agent is taking a step in (either train/val/test env with seed or no seed)\n",
    "        obs : \n",
    "            the current observation from the environment\n",
    "        epsilon : float\n",
    "            the current exploration rate\n",
    "            \n",
    "        Return:\n",
    "        ------------\n",
    "\n",
    "        action\n",
    "            the next action that the agent takes\n",
    "        '''\n",
    "        if np.random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                if self.cuda_enabled:\n",
    "                    state_tensor = torch.tensor(obs, dtype=torch.float32, device='cuda').unsqueeze(0)\n",
    "                else:\n",
    "                    state_tensor = torch.FloatTensor(obs).unsqueeze(0)\n",
    "                q_values = self.Q_net(state_tensor)\n",
    "                action = q_values.argmax().item()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def prefill_replay(self):\n",
    "        obs,_ = self.env.reset()\n",
    "        for _ in range(self.min_replay_size):\n",
    "            action = self.env.action_space.sample()\n",
    "            next_obs, reward, term, trunc, _ = self.env.step(action)\n",
    "            done = term or trunc\n",
    "\n",
    "            self.replay_buffer.append((obs, action, reward, next_obs, done))\n",
    "            obs = next_obs if not done else self.env.reset()[0]\n",
    "\n",
    "    def policy_eval(self, env: gym.Env, n_episode_test = 500, verbose = 0):\n",
    "        ''' Assess the average reward when following a q_network in a test environment with random state initialization\n",
    "        \n",
    "        Parameters:\n",
    "        env : gymnasium environment\n",
    "            - Can be either the self.env_test or self.env_val environment\n",
    "\n",
    "        '''\n",
    "\n",
    "        total_reward = 0\n",
    "        for i in range(n_episode_test):\n",
    "            obs,_ = env.reset()\n",
    "            done = False\n",
    "            eps_reward = 0\n",
    "\n",
    "            while not done:                 # Step thorugh the episode deterministically (no exploration)\n",
    "                action = self.eps_greedy_policy(env, obs, epsilon=0)\n",
    "                next_obs, reward, term, trunc, _ = env.step(action)\n",
    "\n",
    "                eps_reward += reward\n",
    "\n",
    "                obs = next_obs\n",
    "                done = term or trunc\n",
    "        \n",
    "            total_reward += eps_reward\n",
    "            if verbose:\n",
    "                    print(f\"Validation episode {i+1:3d}/{n_episode_test}  |   Reward = {eps_reward:4.0f}\",end=\"\\r\")\n",
    "        average_reward = total_reward / n_episode_test\n",
    "        return average_reward\n",
    "    \n",
    "    def EMA_filter(self, reward: list, alpha):\n",
    "        ''' Function that runs an exponential moving average filter along a datastream '''\n",
    "        output = np.zeros(len(reward)+1)\n",
    "        output[0] = reward[0]\n",
    "        for idx, item in enumerate(reward):\n",
    "            output[idx+1] = (1 - alpha) * output[idx] + alpha * item\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def plot_reward_hist(self, alpha = 0.1):\n",
    "        ''' Function that plots the reward and filtered reward per episode, then saves the plot in a specified save directory'''\n",
    "        n_episodes= len(self.reward_history)\n",
    "        episodes = range(n_episodes)\n",
    "        filtered_reward_hist = self.EMA_filter(self.reward_history, alpha)\n",
    "\n",
    "        plt.figure(figsize=(20,6))\n",
    "        plt.plot(episodes, self.reward_history[:n_episodes], color = \"blue\")\n",
    "        plt.plot(episodes, filtered_reward_hist[:n_episodes], color = \"red\")\n",
    "        plt.title(f'Total reward per episode - {self.hyperparam_config}')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Reward')\n",
    "        plt.legend(['Total reward','Filtered reward'])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if self.save_path:\n",
    "            plt.savefig(os.path.join(self.save_path,'reward_history.png'))\n",
    "        plt.show()\n",
    "    \n",
    "    def save_model(self):\n",
    "        ''' Function to save the model and optimizer state_dict for inference or continued training '''\n",
    "        self.model_path = os.path.join(self.save_path, 'q_network_checkpoint.pth')\n",
    "        torch.save({\n",
    "            'model_state_dict': self.Q_net.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        ''' This code overwrite the Q_net with the parameters store in the instance's save_path '''\n",
    "        checkpoint = torch.load(self.model_path)\n",
    "        self.Q_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "    def DDQN_train(self):\n",
    "        ''' Function to train a policy for a set of hyperparameters '''\n",
    "\n",
    "        msg = \"Training ended, no good model found!\"\n",
    "\n",
    "        self.replay_buffer = deque(maxlen = self.buffer_size)\n",
    "        self.prefill_replay()\n",
    "        self.reward_history = np.zeros(self.episode_train)\n",
    "        self.eps = self.eps_start\n",
    "        step_count = 0\n",
    "        episode = 0\n",
    "        target_network_update_count = 0\n",
    "\n",
    "        # Control of early stopping\n",
    "        consecutive_pass_count = 0           # Number of consecutive episodes where performance exceeds a threshold\n",
    "        CONSECUTIVE_PASS_LIMIT = 3          # No. of consecutive episodes with higher performance than reward limit\n",
    "        EPISODE_REWARD_LIMIT = SUCCESS_CRITERIA\n",
    "        best_reward = 0\n",
    "        performance_crit = False\n",
    "        train_terminated = False\n",
    "\n",
    "        _, self.hyperparam_config, self.save_path = self.create_directory()\n",
    "        self.train_time_start = time.time()\n",
    "        while not train_terminated:     # Experiment level - loop through episodes\n",
    "            obs, _ = self.env.reset(seed=self.seed)\n",
    "            eps_rewards = 0\n",
    "        \n",
    "            while True:                 # Episode level - loop through steps\n",
    "                action = self.eps_greedy_policy(self.env, obs, epsilon = self.eps)\n",
    "\n",
    "                # Interact with the environment\n",
    "                next_obs, reward, term, trunc, _ = self.env.step(action)\n",
    "                done = term or trunc\n",
    "                self.replay_buffer.append((obs, action, reward, next_obs, done))\n",
    "                obs = next_obs\n",
    "                eps_rewards += reward\n",
    "                step_count += 1\n",
    "\n",
    "                # Train the Q-net using a batch of samples from the experience replay\n",
    "                if len(self.replay_buffer) >= self.batch_size:\n",
    "                    batch = random.sample(self.replay_buffer, self.batch_size)\n",
    "                    states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "                    states =        torch.tensor(np.array(states),      dtype = torch.float32,  device='cuda' if self.cuda_enabled else 'cpu')           # Shape of (BATCH_SIZE, 4). Data structure of [[p1 v1 theta1 dtheta1], [p2 v2 theta2 dtheta2], ...]\n",
    "                    actions =       torch.tensor(actions,               dtype = torch.long,     device='cuda' if self.cuda_enabled else 'cpu').unsqueeze(1)        # Must unsqueeze to have shape (BATCH_SIZE, 1). From [a1, a2, ...] to [[a1], [a2], ... [a_BATCH_SIZE]]\n",
    "                    rewards =       torch.tensor(rewards,               dtype = torch.float32,  device='cuda' if self.cuda_enabled else 'cpu').unsqueeze(1)\n",
    "                    next_states =   torch.tensor(np.array(next_states), dtype = torch.float32,  device='cuda' if self.cuda_enabled else 'cpu')\n",
    "                    dones =         torch.tensor(dones,                 dtype = torch.float32,  device='cuda' if self.cuda_enabled else 'cpu').unsqueeze(1)\n",
    "                    \n",
    "                    # Compute targets using target network Q(s',a',w_i^-)\n",
    "                    # TODO - Change this from DQN to DDQN code\n",
    "                    with torch.no_grad():\n",
    "                        # Select the maximizing action according to the online behaviour net\n",
    "                        optimal_next_actions_online = self.Q_net(next_states).argmax(dim=1,keepdim=True)\n",
    "                        \n",
    "                        # Find the target Q value of the maximizing action according to the target net\n",
    "                        target_q_values = self.target_net(next_states).gather(1,optimal_next_actions_online)\n",
    "                        \n",
    "                        targets = rewards + self.gamma * target_q_values * (1 - dones)       # (1-dones) to avoid over estimating the value of terminal states. The target should only be the reward in the terminal states   # (1-dones) to avoid over estimating the value of terminal states. The target should only be the reward in the terminal states\n",
    "                \n",
    "                    # Compute the current Q values for the actions taken Q(s,a,w_i)\n",
    "                    q_values = self.Q_net(states).gather(1, actions)         # obtain the q_values associated to the actual action taken in each sample\n",
    "\n",
    "                    # Update the parameters of the behaviour q_network\n",
    "                    loss = nn.MSELoss()(q_values, targets)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                # Periodically update the target network by loading the weights from the behavior network\n",
    "                if step_count % self.target_update_freq == 0:\n",
    "                    target_network_update_count += 1\n",
    "                    self.target_net.load_state_dict(self.Q_net.state_dict())\n",
    "\n",
    "                if done:        # End of a training episode\n",
    "                    break\n",
    "\n",
    "            # Decay epsilon after an episode\n",
    "            self.eps = max(self.eps_end, self.eps - (self.eps_start - self.eps_end)/self.eps_decay)\n",
    "\n",
    "            self.reward_history[episode] = eps_rewards\n",
    "            # print(f\"Episode {episode:5d}: Total reward = {eps_rewards:5.1f}, Epsilon = {epsilon:.3f}, Step count = {step_count:5d}, Target update count = {target_network_update_count:3d}\")\n",
    "            # print(f\"Average reward {sum(reward_history[:episode])/(episode+1):.2f}\")\n",
    "\n",
    "            \n",
    "            if episode % 10 == 0:                   # print progress periodically\n",
    "                print(f\"Episode {episode:5d}/{self.episode_train}: Total reward = {eps_rewards:5.1f}, Epsilon = {self.eps:.3f}\", end = \"\\r\")\n",
    "\n",
    "            # Early stopping condition\n",
    "            if eps_rewards >= EPISODE_REWARD_LIMIT:\n",
    "                test_reward = self.policy_eval(self.env_val, 100)       \n",
    "                self.val_history[episode] = [eps_rewards, test_reward]\n",
    "\n",
    "                if test_reward >= best_reward:           # Set the new best reward\n",
    "                    best_reward = test_reward\n",
    "                    self.save_model()\n",
    "                    self.best_model_episode = episode\n",
    "                    msg = f\"Training terminated due to episode limit, best model saved at episode {self.best_model_episode:5d}\"\n",
    "                if test_reward > EPISODE_REWARD_LIMIT: \n",
    "                    consecutive_pass_count += 1\n",
    "                else: consecutive_pass_count = 0\n",
    "            else:\n",
    "                consecutive_pass_count = 0\n",
    "                \n",
    "            # Performance criteria - if good results for several episodes => training performance satisfied and terminate early\n",
    "            if consecutive_pass_count >= CONSECUTIVE_PASS_LIMIT:\n",
    "                self.save_model()\n",
    "                self.best_model_episode = episode\n",
    "                performance_crit = True \n",
    "                msg = f\"Early termination at episode {episode:5d}, desired performance reached\"\n",
    "\n",
    "\n",
    "            episode += 1\n",
    "\n",
    "            # Checking for early training termination or truncation\n",
    "            train_terminated = (episode >= self.episode_train) or (performance_crit)\n",
    "        self.train_time = time.time() - self.train_time_start\n",
    "\n",
    "        print(f\"\\nRuntime - {self.train_time:5.2f}\")\n",
    "\n",
    "        print(msg)\n",
    "        return\n",
    "\n",
    "    def DDQN_record(self):\n",
    "        ''' Method to plot the reward history and store the data in the current run folder '''\n",
    "\n",
    "        # Load the best Q net parameter from the experiment\n",
    "        self.load_model()\n",
    "\n",
    "        # Average test reward of the resulting policy\n",
    "        self.env_test = gym.make('CartPole-v1')\n",
    "        print(\"\\nTesting the Q_net\")\n",
    "        average_reward = self.policy_eval(self.env_test, n_episode_test=500, verbose = 1)\n",
    "        print(f\"\\nTest average reward {average_reward:4.2f}\")\n",
    "\n",
    "        # Store the validation hisotry and average test reward in the param_config JSON file\n",
    "        param_path = os.path.join(self.save_path,'param_config.json')\n",
    "        if os.path.exists(param_path):\n",
    "            with open(param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {}\n",
    "        data['runtime'] = self.train_time\n",
    "        data['best_model_at'] = self.best_model_episode\n",
    "        data['val_history'] = self.val_history\n",
    "        data['test_result'] = average_reward\n",
    "\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Plot\n",
    "        self.plot_reward_hist()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a0964",
   "metadata": {},
   "source": [
    "## DDQN Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b48396",
   "metadata": {},
   "source": [
    "Using itertools to loop through each combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02fcce5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/4 - model DQN_MLP_v0, lr=0.0001, buffer=5000, target_freq=1000, gamma=0.95, eps_decay=5000, batch_size=32\n",
      "Episode  3710/5000: Total reward = 500.0, Epsilon = 0.332\n",
      "Runtime - 1118.27\n",
      "Early termination at episode  3714, desired performance reached\n",
      "\n",
      "Testing the Q_net\n",
      "Validation episode 500/500  |   Reward =  500\n",
      "Test average reward 464.56\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2/4 - model DQN_MLP_v0, lr=0.0005, buffer=5000, target_freq=1000, gamma=0.95, eps_decay=5000, batch_size=32\n",
      "Episode  1430/5000: Total reward =  45.0, Epsilon = 0.742\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# # Training information\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, buffer=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBUFFER_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, target_freq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_UPDATE_FREQ\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, gamma=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGAMMA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, eps_decay=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPS_DECAY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBATCH_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDDQN_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m experiment\u001b[38;5;241m.\u001b[39mDDQN_record()\n",
      "Cell \u001b[1;32mIn[18], line 295\u001b[0m, in \u001b[0;36mDDQN_experiment.DDQN_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m batch \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m    293\u001b[0m states, actions, rewards, next_states, dones \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m--> 295\u001b[0m states \u001b[38;5;241m=\u001b[39m        torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m,      dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32,  device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)           \u001b[38;5;66;03m# Shape of (BATCH_SIZE, 4). Data structure of [[p1 v1 theta1 dtheta1], [p2 v2 theta2 dtheta2], ...]\u001b[39;00m\n\u001b[0;32m    296\u001b[0m actions \u001b[38;5;241m=\u001b[39m       torch\u001b[38;5;241m.\u001b[39mtensor(actions,               dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong,     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)        \u001b[38;5;66;03m# Must unsqueeze to have shape (BATCH_SIZE, 1). From [a1, a2, ...] to [[a1], [a2], ... [a_BATCH_SIZE]]\u001b[39;00m\n\u001b[0;32m    297\u001b[0m rewards \u001b[38;5;241m=\u001b[39m       torch\u001b[38;5;241m.\u001b[39mtensor(rewards,               dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32,  device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_enabled \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import time\n",
    "keys, values = zip(*param_grid.items())\n",
    "# keys, values = param_grid.keys(), param_grid.values()\n",
    "num_config = len(list(itertools.product(*values)))\n",
    "\n",
    "# Set fixed seed\n",
    "seed = 42\n",
    "np.random.seed(seed); random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "for idx, v in enumerate(itertools.product(*values)):\n",
    "\n",
    "    # Unpacking the hyperparameter configurations\n",
    "    config = dict(zip(keys,v))\n",
    "    MODEL_NAME = config['MODEL']                            # Name of the model: \"DQN_MLP_v0\", \"DQN_MLP_v1\"\n",
    "    MODEL_CLASS = model_registry[MODEL_NAME]['class']       # The model class: QNet_MLP,...\n",
    "    MODEL_CONFIG = model_registry[MODEL_NAME]['config']     # The architecture of the model\n",
    "    match = re.search(r'v\\d+',MODEL_NAME)                   \n",
    "    MODEL_ID = match.group(0) if match else 404             # The model id: \"v0\", \"v1\"\n",
    "\n",
    "    LR = config['LR']\n",
    "    BUFFER_SIZE = config['BUFFER_SIZE']\n",
    "    MIN_REPLAY_SIZE = config['MIN_REPLAY_SIZE']\n",
    "    TARGET_UPDATE_FREQ = config['TARGET_UPDATE_FREQ']\n",
    "    GAMMA = config['GAMMA']\n",
    "    EPS_START = config['EPSILON_START']\n",
    "    EPS_END = config['EPSILON_END']\n",
    "    EPS_DECAY = config['EPSILON_DECAY']\n",
    "    EPISODE_TRAIN = config['EPISODE_TRAIN']\n",
    "    BATCH_SIZE = config['BATCH_SIZE']\n",
    "\n",
    "\n",
    "    experiment = DDQN_experiment(MODEL_NAME, model_registry, \n",
    "                                 LR, BUFFER_SIZE, TARGET_UPDATE_FREQ, GAMMA, \n",
    "                                 EPS_START, EPS_DECAY, EPS_END, \n",
    "                                 BATCH_SIZE, seed, cuda_enabled=CUDA_ENABLED)\n",
    "    \n",
    "    # # Training information\n",
    "    print(f'Trial {idx+1}/{num_config} - model {MODEL_NAME}, lr={LR}, buffer={BUFFER_SIZE}, target_freq={TARGET_UPDATE_FREQ}, gamma={GAMMA}, eps_decay={EPS_DECAY}, batch_size={BATCH_SIZE}')\n",
    "    experiment.DDQN_train()\n",
    "    experiment.DDQN_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ccf53",
   "metadata": {},
   "source": [
    "## Load and Simulate Saved Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17800428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(q_network: nn.Module, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    q_network.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c06f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy_policy(env, obs, epsilon: float, q_network: QNet_MLP):\n",
    "    ''' Function to take an action according to an epsilon-greedy policy and a Q-network'''\n",
    "    if np.random.random() < epsilon:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(obs).unsqueeze(0)\n",
    "            q_values = q_network(state_tensor)\n",
    "            action = q_values.argmax().item()\n",
    "\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1bfcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model after training\n",
    "\n",
    "# Manually select a folder/run to load\n",
    "run_number = 'run_00003'\n",
    "\n",
    "# Find the paths to the param_config and model checkpoint\n",
    "BASE_DIR = os.getcwd()\n",
    "RESULT_DIR = os.path.join(BASE_DIR,'cartpole_DDQN_results')\n",
    "RUN_DIR = os.path.join(RESULT_DIR, run_number)\n",
    "MODEL_PATH = os.path.join(RUN_DIR,'q_network_checkpoint.pth')\n",
    "\n",
    "# Find the model configuration\n",
    "with open(os.path.join(RUN_DIR,\"param_config.json\"),'r') as f:\n",
    "    data = json.load(f)\n",
    "model_id = 'DQN_MLP_' + data['parameters']['model_id']\n",
    "model_config = model_registry[model_id]['config']\n",
    "\n",
    "# Create a visual simulation of the network\n",
    "RENDER_MODE = \"human\"\n",
    "env_test_visual = gym.make(\"CartPole-v1\",render_mode=RENDER_MODE)\n",
    "obs_space = env_test_visual.observation_space.shape[0]\n",
    "act_space = env_test_visual.action_space.n\n",
    "num_test = 1\n",
    "\n",
    "# Create the model according to the model version in the model registry\n",
    "q_network_loaded = QNet_MLP(obs_space, act_space, model_config)\n",
    "load_model(q_network_loaded, MODEL_PATH)\n",
    "\n",
    "for episode in range(num_test):\n",
    "    obs, _ = env_test_visual.reset()\n",
    "    done = False\n",
    "    eps_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = eps_greedy_policy(env_test_visual, obs, epsilon = 0, q_network=q_network_loaded)\n",
    "        next_obs, reward, term, trunc, _ = env_test_visual.step(action)\n",
    "\n",
    "        done = term or trunc\n",
    "        eps_reward += reward\n",
    "        obs = next_obs\n",
    "    \n",
    "    print(f\"Reward from episode {episode:3d} is {eps_reward}\")\n",
    "\n",
    "env_test_visual.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43fea3",
   "metadata": {},
   "source": [
    "# REINFORCE Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b418380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym             # To create the inverted pendulum environment\n",
    "import torch                        \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json                         # to save parameters and results\n",
    "import time                         # to monitor training & validation time\n",
    "from datetime import datetime       # to create a log of runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7c33f",
   "metadata": {},
   "source": [
    "## Parameter & Class Definitions\n",
    "\n",
    "Define the hyperparameters of the experiment(s), the policy network and value network classes, and the REINFORCE experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001541f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'MODEL': [\"Policy_MLP_v0\", \"Policy_MLP_v1\"],\n",
    "    'ALPHA' : [5e-4, 1e-3],\n",
    "    'BETA' : [1e-3, 5e-3],\n",
    "    'GAMMA': [0.95, 0.98],\n",
    "    'N_EPISODE_TRAIN': [5000]\n",
    "}\n",
    "\n",
    "N_EPISODE_TEST = 5\n",
    "CUDA_ENABLED = False\n",
    "SUCCESS_CRITERIA = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415778a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[64,64]):\n",
    "        ''' Initialize the model and create a list of layers '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for layer_size in hidden_layers:\n",
    "            self.layers.append(nn.Linear(input_dim, layer_size))\n",
    "            input_dim = layer_size\n",
    "\n",
    "        self.layers.append(nn.Linear(input_dim, self.output_dim))\n",
    "        if CUDA_ENABLED: self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input = torch.relu(layer(input))\n",
    "        logits = self.layers[-1](input)\n",
    "        probs = torch.softmax(logits,dim=-1)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa5305f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[32,32]):\n",
    "        ''' Initialize the model and create a list of layers '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for layer_size in hidden_layers:\n",
    "            self.layers.append(nn.Linear(input_dim, layer_size))\n",
    "            input_dim = layer_size\n",
    "\n",
    "        self.layers.append(nn.Linear(input_dim, self.output_dim))\n",
    "        if CUDA_ENABLED: self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input = torch.relu(layer(input))\n",
    "        output = self.layers[-1](input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1aa8a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = {\n",
    "    \"Policy_MLP_v0\": {\n",
    "        'class': PolicyNet,\n",
    "        'config': [64,32]\n",
    "    },\n",
    "    'Policy_MLP_v1': {\n",
    "        'class': PolicyNet,\n",
    "        'config': [64,32],\n",
    "        'value_class': ValueNet,\n",
    "        'value_config': [32]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cba14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class REINFORCE():\n",
    "    def __init__(self, model_name: str,\n",
    "                 model_registry,\n",
    "                 alpha: float,          # learning rate of the policy net\n",
    "                 beta: float,           # learning rate of the state value net\n",
    "                 gamma: float,          # discount rate in RL\n",
    "                 n_episode_train,\n",
    "                 result_folder = 'cartpole_REINFORCE_results',\n",
    "                 seed = 42,\n",
    "                 cuda_enabled = False,\n",
    "                 verbose = True):\n",
    "        \n",
    "        self.N_EPISODE_TRAIN = n_episode_train\n",
    "        self.result_folder = result_folder\n",
    "        self.SEED = seed\n",
    "        self.CUDA_ENABLED = cuda_enabled\n",
    "        self.VERBOSE = verbose\n",
    "        self.LOG_PERIOD = 50\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # Initialize the train and validation environments\n",
    "        self.env = gym.make(\"CartPole-v1\")\n",
    "        self.env_val = gym.make(\"CartPole-v1\")\n",
    "        self.obs_space = self.env.observation_space.shape[0]\n",
    "        self.act_space = self.env.action_space.n\n",
    "        \n",
    "        ''' Experiment hyperparameters '''\n",
    "        # Policy model configuration\n",
    "        self.model_name = model_name\n",
    "        self.model_class = model_registry[self.model_name]['class']\n",
    "        self.model_config = model_registry[self.model_name]['config']\n",
    "        match = re.search(r'v\\d+', self.model_name)\n",
    "        self.model_id = match.group(0) if match else 404\n",
    "\n",
    "        # Initialize the policy network\n",
    "        self.policy_net = self.model_class(self.obs_space, self.act_space, self.model_config)\n",
    "        self.policy_net.apply(self.init_weights)\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr = self.alpha)\n",
    "\n",
    "        # REINFORCE w/ baseline => Value model configuration (if value_class exists)\n",
    "        if 'value_class' in model_registry[self.model_name]:\n",
    "            if model_registry[self.model_name]['value_class']:\n",
    "                self.value_class = model_registry[self.model_name]['value_class']\n",
    "                self.value_config = model_registry[self.model_name]['value_config']\n",
    "                self.value_net = self.value_class(self.obs_space, 1, self.value_config)\n",
    "                self.value_net.apply(self.init_weights)\n",
    "                self.value_optimizer = optim.Adam(self.value_net.parameters(), lr = self.beta)\n",
    "                self.BASELINE = True\n",
    "        else: \n",
    "            self.BASELINE = False\n",
    "\n",
    "        self.save_path = ''\n",
    "        self.model_path = ''\n",
    "        self.hyperparam_config = ''\n",
    "        self.reward_history = []\n",
    "        self.val_history = {}                                           # Monitor which episode had a validation run, the train reward, and the validation (test) reward \n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def create_directory(self):\n",
    "        ''' Function that creates directory to save model state_dict, architecture, training configuration, and history\n",
    "\n",
    "        Parameters: \n",
    "        ------------\n",
    "        (hyperparameters for differentiating between different directory)\n",
    "        \n",
    "        lr : float\n",
    "            the learning rate to optimize the Q network\n",
    "        gamma : float \n",
    "            the discount rate in Q learning\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        name_codified : str\n",
    "            the shortened name for the current experiment \n",
    "        hyperparameters_codified : str\n",
    "            the shortened string of hyperparameter configuration\n",
    "        OUTPUT_DIR : path\n",
    "            the directory to which the training results and model (state_dict and architecture) will be saved\n",
    "        '''\n",
    "        timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "        BASE_DIR = os.getcwd()\n",
    "        RESULT_DIR = os.path.join(BASE_DIR, self.result_folder)\n",
    "        os.makedirs(RESULT_DIR, exist_ok=True)      # Create the directory if one does not already exist\n",
    "\n",
    "        # Find the trial # of the latest run\n",
    "        existing_runs = [d for d in os.listdir(RESULT_DIR) if os.path.isdir(os.path.join(RESULT_DIR,d))]\n",
    "        run_numbers = [int(re.search(r'run_(\\d{5})',d).group(1)) for d in existing_runs if re.match(r'run_\\d{5}',d)]\n",
    "        trial_number = max(run_numbers,default=-1)+1\n",
    "\n",
    "        # Create a folder for the run\n",
    "        name_codified = f\"run_{trial_number:05d}\"\n",
    "        OUTPUT_DIR = os.path.join(RESULT_DIR,name_codified)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)      # Create the directory\n",
    "\n",
    "        # Append the mapping from run # to hyperparameter configuration in a JSON file inside RESULT_DIR\n",
    "        trial_to_param_path = os.path.join(RESULT_DIR,'trial_to_param.json')\n",
    "        if os.path.exists(trial_to_param_path):\n",
    "            with open(trial_to_param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {name_codified: \"\"}\n",
    "\n",
    "        hyperparam_codified = \"REINFORCE_\"\n",
    "        hyperparam_codified += \"baseline_\" if self.BASELINE else \"\"\n",
    "        hyperparam_codified += \"OOP_\"\n",
    "        hyperparam_codified += \"CUDA_\" if self.CUDA_ENABLED else \"nCUDA_\"\n",
    "        hyperparam_codified += f\"{self.model_id}_{self.alpha}_\"\n",
    "        hyperparam_codified += f\"{self.beta}_\" if self.BASELINE else \"\"\n",
    "        hyperparam_codified += f\"{self.gamma}\"\n",
    "\n",
    "        hyperparam_codified_time = f\"{timestamp}_\" + hyperparam_codified\n",
    "\n",
    "        data[name_codified] = hyperparam_codified_time\n",
    "\n",
    "        with open(trial_to_param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Store the training configs in JSON file\n",
    "        training_params = {\n",
    "            'OOP':                  True,\n",
    "            'CUDA':                 self.CUDA_ENABLED,\n",
    "            'device':               torch.cuda.get_device_name(torch.cuda.current_device()),\n",
    "            'model_id':             self.model_id,\n",
    "            'alpha':                self.alpha,\n",
    "            'gamma':                self.gamma,\n",
    "        }\n",
    "        if self.BASELINE: training_params['beta'] = self.beta\n",
    "\n",
    "        # Store training parameters in each run \n",
    "        param_path = os.path.join(OUTPUT_DIR, \"param_config.json\")\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump({\"parameters\": training_params}, f, indent=2)\n",
    "\n",
    "        return name_codified, hyperparam_codified, OUTPUT_DIR\n",
    "    \n",
    "    def get_returns(self, eps_reward_history):\n",
    "        ''' Function to calculate the return of each time step when given a list of rewards \n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        rewards : list\n",
    "            a list of rewards achieved throughout the agent's trajectory\n",
    "        gamma   : float\n",
    "            the discount factor\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        returns : list\n",
    "            a list of returns G_t at each step of the trajectory\n",
    "            \n",
    "        For each step of th trajectory (of length T):\n",
    "        - Extract the rewards from that step onward\n",
    "        - Each step is multiplied by the corresponding gamma ^ index \n",
    "            the first reward received from leaving the state is not discounted\n",
    "            the last reward received from the trajectory is discouned by gamma ^ (T-1)\n",
    "        - Sum these values together to obtain the return at each step\n",
    "        '''\n",
    "        returns = np.zeros(len(eps_reward_history))\n",
    "        gamma = self.gamma\n",
    "        \n",
    "        for step, _ in enumerate(eps_reward_history):          # step through the \"trajectory\" or history of reward\n",
    "            step_reward = eps_reward_history[step:]            # reward from the current step onward\n",
    "\n",
    "            # List of discounted rewards at each time step\n",
    "            return_val = [gamma ** i * step_reward[i] for i in range(len(step_reward))]\n",
    "            return_val = sum(return_val)\n",
    "            \n",
    "            returns[step] = return_val\n",
    "        return returns\n",
    "\n",
    "    def policy_eval(self, env: gym.Env, n_episode_test = 500, verbose = True):\n",
    "        ''' Assess the average reward when following the policy net in a test environment with random state initialization\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        env : gymnasium environment\n",
    "            this environment can be either the self.env_test or self.env_val environment (whether they are the same)\n",
    "        n_episode_test : int \n",
    "            the number of evaluation episodes\n",
    "        verbose : bool\n",
    "            whether to print testing information \n",
    "\n",
    "        Return:\n",
    "        ----------\n",
    "        average_reward : float\n",
    "            the average reward received from running the test\n",
    "        '''\n",
    "\n",
    "        total_reward = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_episode_test):\n",
    "                obs,_ = env.reset()\n",
    "                done = False\n",
    "                eps_reward = 0\n",
    "\n",
    "                while not done:                 # Step thorugh the episode deterministically (no exploration)\n",
    "                    obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "                    action_probs = self.policy_net(obs_tensor)\n",
    "                    action_dist = Categorical(action_probs)\n",
    "                    action = action_dist.sample()\n",
    "                    next_obs, reward, term, trunc, _ = env.step(action.item())\n",
    "\n",
    "                    # Strategy 1 - Accumulate the reward from the environment\n",
    "                    eps_reward += reward\n",
    "\n",
    "                    # TODO - Strategy 2 - evaluate the strategy based on states\n",
    "\n",
    "                    obs = next_obs\n",
    "                    done = term or trunc\n",
    "            \n",
    "                total_reward += eps_reward\n",
    "                if verbose:\n",
    "                    print(f\"Validation episode {i+1:3d}/{n_episode_test}  |   Reward = {eps_reward:4.0f}\",end=\"\\r\")\n",
    "        average_reward = total_reward / n_episode_test\n",
    "        \n",
    "        return average_reward\n",
    "    \n",
    "    def EMA_filter(self, reward: list, alpha):\n",
    "        ''' Function that runs an exponential moving average filter along a datastream '''\n",
    "        output = np.zeros(len(reward)+1)\n",
    "        output[0] = reward[0]\n",
    "        for idx, item in enumerate(reward):\n",
    "            output[idx+1] = (1 - alpha) * output[idx] + alpha * item\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def plot_reward_hist(self, alpha = 0.1):\n",
    "        ''' Function that plots the reward and filtered reward per episode, then saves the plot in a specified save directory'''\n",
    "        n_episodes= len(self.reward_history)\n",
    "        episodes = range(n_episodes)\n",
    "        filtered_reward_hist = self.EMA_filter(self.reward_history, alpha)\n",
    "        fig, axes = plt.subplots(2,1, figsize=(20,12))\n",
    "        axes[0].plot(episodes, self.reward_history[:n_episodes], label = 'Total reward', color = \"blue\")\n",
    "        axes[0].plot(episodes, filtered_reward_hist[:n_episodes], label = 'Filtered reward', color = \"red\")\n",
    "        axes[0].set_title(f'Total reward per episode - {self.hyperparam_config}')\n",
    "        axes[0].set_xlabel('Episode')\n",
    "        axes[0].set_ylabel('Reward')\n",
    "        axes[0].legend()\n",
    "\n",
    "        n_episodes= len(self.value_history)\n",
    "        episodes = range(n_episodes)\n",
    "        axes[1].plot(episodes, self.value_history[:n_episodes], label = \"v(s_0)\", color = \"blue\")\n",
    "        # If using baseline with a value estimation model, plot this as well\n",
    "        if self.BASELINE: axes[1].plot(episodes, self.value_est_history[:n_episodes], label = r\"$\\hat v$(s_0)\", color = \"red\")\n",
    "        axes[1].set_title(f'Return in state s_0 - {self.hyperparam_config}')\n",
    "        axes[1].set_xlabel('Episode')\n",
    "        axes[1].set_ylabel('v(s_0)')\n",
    "        axes[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if self.save_path:\n",
    "            plt.savefig(os.path.join(self.save_path,'reward_history.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self):\n",
    "        ''' Function to save the model and optimizer state_dict for inference or continued training '''\n",
    "        self.model_path = os.path.join(self.save_path, 'q_network_checkpoint.pth')\n",
    "        torch.save({\n",
    "            'model_state_dict': self.policy_net.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        ''' This code overwrite the Q_net with the parameters store in the instance's save_path '''\n",
    "        checkpoint = torch.load(self.model_path)\n",
    "        self.policy_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    def train_policy(self):\n",
    "        msg = \"Training ended with no good model found :<\"\n",
    "\n",
    "        # Create the directory to store results\n",
    "        self.run_number, self.hyperparam_config, self.save_path = self.create_directory()\n",
    "\n",
    "        # Training information\n",
    "        if self.BASELINE: title = f\"REINFORCE baseline model {self.model_name}, alpha={self.alpha}, beta={self.beta}, gamma={self.gamma}\" \n",
    "        else: title = f\"REINFORCE w/o baseline model {self.model_name}, alpha={self.alpha}, gamma={self.gamma}\" \n",
    "        if self.VERBOSE: print(title)\n",
    "\n",
    "        self.reward_history = []                # Track the total reward per episode\n",
    "        self.val_history = {}                   # Reset the validation history\n",
    "        self.policy_loss_history = []           # History of loss throughout training\n",
    "        self.value_loss_history = []\n",
    "        self.value_history = []                 # History of the v(s_0) calculated using G_t throughout training\n",
    "        if self.BASELINE: self.value_est_history = []             # History of the \\hat v(s_0) calculated using the value net (baseline case)\n",
    "        self.val_time = 0                       # Time used for validation (s)\n",
    "        episode = 0\n",
    "\n",
    "        # Control of early stopping\n",
    "        consecutive_pass_count = 0\n",
    "        CONSECUTIVE_PASS_LIMIT = 3\n",
    "        EPISODE_REWARD_LIMIT = SUCCESS_CRITERIA\n",
    "        best_reward = 0\n",
    "        self.best_model_episode = None\n",
    "        performance_crit = False                # Whether desired performance is met consistently\n",
    "        train_terminated = False\n",
    "        \n",
    "\n",
    "        self.train_time_start = time.time()\n",
    "        while not train_terminated:             # Experiment level - loop through episodes\n",
    "            obs, _ = self.env.reset(seed=self.SEED)\n",
    "            obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "            done = False\n",
    "            step = 0\n",
    "            eps_reward_history = []\n",
    "            log_prob_history = []\n",
    "\n",
    "            if self.BASELINE:\n",
    "                obs_history = []\n",
    "                obs_history.append(obs_tensor)\n",
    "                \n",
    "\n",
    "            while not done:                     # Episode level - loop through steps in an episode\n",
    "                step += 1\n",
    "                action_probs = self.policy_net(obs_tensor)\n",
    "                action_dist = Categorical(action_probs)\n",
    "                action = action_dist.sample()\n",
    "\n",
    "                next_obs, reward, term, trunc, _ = self.env.step(action.item())\n",
    "\n",
    "                if self.BASELINE: obs_history.append(obs_tensor)\n",
    "                eps_reward_history.append(reward)\n",
    "                log_prob_history.append(action_dist.log_prob(action))\n",
    "                \n",
    "                obs_tensor = torch.tensor(next_obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "                done = term or trunc\n",
    "            \n",
    "            # Post episode calculations - returns, total episode reward, and loss\n",
    "            returns = self.get_returns(eps_reward_history)\n",
    "            returns = torch.tensor(returns, dtype = torch.float32, device='cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "\n",
    "            if self.BASELINE: \n",
    "                obs_history_tensor = torch.stack(obs_history)\n",
    "                # print(obs_history_tensor.shape)\n",
    "                baseline_values = self.value_net(obs_history_tensor)[:-1]\n",
    "                delta = returns.unsqueeze(dim=1) - baseline_values.detach()\n",
    "                # Find loss of the value function and update parameters\n",
    "                value_loss = -torch.sum(baseline_values * delta)\n",
    "                self.value_optimizer.zero_grad()\n",
    "                value_loss.backward()\n",
    "                self.value_optimizer.step()\n",
    "\n",
    "                # Find loss of the policy network and update parameters\n",
    "                policy_loss = - torch.sum(torch.stack(log_prob_history) * delta)\n",
    "                self.optimizer.zero_grad()\n",
    "                policy_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            else:\n",
    "                policy_loss = - torch.sum(torch.stack(log_prob_history) * returns)\n",
    "                self.optimizer.zero_grad()\n",
    "                policy_loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            eps_reward = sum(eps_reward_history)\n",
    "        \n",
    "\n",
    "            self.reward_history.append(eps_reward)     # Total reward of episode\n",
    "            self.policy_loss_history.append(policy_loss)\n",
    "            self.value_history.append(returns[0])\n",
    "            if self.BASELINE:\n",
    "                with torch.no_grad():   # Estimate and store \\hat v(s_0)\n",
    "                    self.value_est_history.append(self.value_net(obs_history[0]).item())\n",
    "\n",
    "            # Optimize the network parameters\n",
    "            \n",
    "            # Periodic data logger\n",
    "            \n",
    "            if episode % self.LOG_PERIOD == 0 and self.VERBOSE:\n",
    "                printout_msg = f\"Episode {episode:5d}/{self.N_EPISODE_TRAIN}: Total reward = {eps_reward:5.1f}   |   G_0 = {returns[0]: 5.2f}\"\n",
    "                if self.BASELINE: printout_msg += fr\"   |   $\\hat v(s_0)$ = {self.value_est_history[-1]:6.2f}\" \n",
    "                print(printout_msg, end='\\r')\n",
    "\n",
    "            # Early stopping condition\n",
    "            if eps_reward >= EPISODE_REWARD_LIMIT:\n",
    "                # Evaluate the current good policy and record the validation time\n",
    "                self.val_time_start = time.time()\n",
    "                test_reward = self.policy_eval(self.env_val, 20,verbose=False)\n",
    "                self.val_time += time.time() - self.val_time_start\n",
    "\n",
    "                self.val_history[episode] = [eps_reward, test_reward]\n",
    "\n",
    "                if test_reward >= best_reward:           # Set the new best reward\n",
    "                    best_reward = test_reward\n",
    "                     \n",
    "                    self.best_model_episode = episode\n",
    "                    msg = f\"Training terminated due to episode limit, best model saved at episode {self.best_model_episode:5d}\"\n",
    "                if test_reward > EPISODE_REWARD_LIMIT: \n",
    "                    consecutive_pass_count += 1\n",
    "                else: consecutive_pass_count = 0\n",
    "            else:\n",
    "                consecutive_pass_count = 0\n",
    "\n",
    "            # Performance criteria - if good results for several episodes => training performance satisfied and terminate early\n",
    "            if consecutive_pass_count >= CONSECUTIVE_PASS_LIMIT:\n",
    "                self.save_model()\n",
    "                self.best_model_episode = episode\n",
    "                performance_crit = True \n",
    "                msg = f\"Early termination at episode {self.best_model_episode:5d}, desired performance reached\"\n",
    "\n",
    "\n",
    "            episode += 1\n",
    "\n",
    "            # Checking for early training termination or truncation\n",
    "            train_terminated = (episode >= self.N_EPISODE_TRAIN) or (performance_crit)\n",
    "\n",
    "        self.train_time = time.time() - self.train_time_start\n",
    "\n",
    "        print(f\"\\nTotal runtime - {self.train_time:5.2f}\")\n",
    "        print(msg)\n",
    "        return\n",
    "\n",
    "    def record(self):\n",
    "        # Load the best policy net parameter from the experiment\n",
    "        if self.model_path:\n",
    "            self.load_model()\n",
    "\n",
    "        # Average test reward of the resulting policy - if best policy does not exists use the last one\n",
    "        self.env_test = gym.make('CartPole-v1')\n",
    "        print('Testing the best policy network performance')\n",
    "        average_reward = self.policy_eval(self.env_test, n_episode_test=500, verbose=True)\n",
    "        print(f\"\\nValidation average reward {average_reward:4.2f}\")\n",
    "\n",
    "        # Store the validation history and average test reward in the param_config JSON file\n",
    "        param_path = os.path.join(self.save_path, 'param_config.json')\n",
    "        if os.path.exists(param_path):\n",
    "            with open(param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {}\n",
    "\n",
    "        data['runtime'] = self.train_time\n",
    "        data['valtime'] = self.val_time\n",
    "        data['best_model_at'] = self.best_model_episode\n",
    "        data['val_history'] = self.val_history\n",
    "        data['test_result'] = average_reward\n",
    "\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Plot\n",
    "        self.plot_reward_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d2792",
   "metadata": {},
   "source": [
    "## REINFORCE Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1436ee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REINFORCE w/o baseline model Policy_MLP_v0, alpha=0.0005, gamma=0.95\n",
      "Episode   800/5000: Total reward = 285.0   |   G_0 =  20.00\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 31\u001b[0m\n\u001b[0;32m     20\u001b[0m N_EPISODE_TRAIN \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN_EPISODE_TRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     22\u001b[0m REINFORCE_experiment \u001b[38;5;241m=\u001b[39m REINFORCE(MODEL_NAME, \n\u001b[0;32m     23\u001b[0m                                 model_registry,\n\u001b[0;32m     24\u001b[0m                                 alpha \u001b[38;5;241m=\u001b[39m ALPHA,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                 cuda_enabled\u001b[38;5;241m=\u001b[39mCUDA_ENABLED,\n\u001b[0;32m     30\u001b[0m                                 verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 31\u001b[0m \u001b[43mREINFORCE_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m REINFORCE_experiment\u001b[38;5;241m.\u001b[39mrecord()\n",
      "Cell \u001b[1;32mIn[25], line 330\u001b[0m, in \u001b[0;36mREINFORCE.train_policy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBASELINE: obs_history\u001b[38;5;241m.\u001b[39mappend(obs_tensor)\n\u001b[0;32m    329\u001b[0m eps_reward_history\u001b[38;5;241m.\u001b[39mappend(reward)\n\u001b[1;32m--> 330\u001b[0m log_prob_history\u001b[38;5;241m.\u001b[39mappend(\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    332\u001b[0m obs_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(next_obs, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCUDA_ENABLED \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    333\u001b[0m done \u001b[38;5;241m=\u001b[39m term \u001b[38;5;129;01mor\u001b[39;00m trunc\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\distributions\\categorical.py:140\u001b[0m, in \u001b[0;36mCategorical.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[1;32m--> 140\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    142\u001b[0m     value, log_pmf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits)\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\distributions\\distribution.py:315\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m support \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[43msupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_is_all_true(valid):\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected value argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    323\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "keys, values = zip(*param_grid.items())\n",
    "num_config = len(list(itertools.product(*values)))\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed); random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "for idx, v in enumerate(itertools.product(*values)):\n",
    "    # Unpack the hyperparameters configurations\n",
    "    config = dict(zip(keys,v))\n",
    "    MODEL_NAME = config['MODEL']\n",
    "    MODEL_CLASS = model_registry[MODEL_NAME]['class']\n",
    "    MODEL_CONFIG = model_registry[MODEL_NAME]['config']\n",
    "    match = re.search(r'v\\d+',MODEL_NAME)\n",
    "    MODEL_ID = match.group(0) if match else 404\n",
    "\n",
    "    ALPHA = config['ALPHA']\n",
    "    BETA = config['BETA']\n",
    "    GAMMA = config['GAMMA']\n",
    "    N_EPISODE_TRAIN = config['N_EPISODE_TRAIN']\n",
    "    \n",
    "    REINFORCE_experiment = REINFORCE(MODEL_NAME, \n",
    "                                    model_registry,\n",
    "                                    alpha = ALPHA,\n",
    "                                    beta = BETA,\n",
    "                                    gamma = GAMMA,\n",
    "                                    n_episode_train = N_EPISODE_TRAIN,\n",
    "                                    seed=42,\n",
    "                                    cuda_enabled=CUDA_ENABLED,\n",
    "                                    verbose=True)\n",
    "    REINFORCE_experiment.train_policy()\n",
    "    REINFORCE_experiment.record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5a587",
   "metadata": {},
   "source": [
    "## Load and Simulate a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(q_network: nn.Module, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    q_network.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually select a folder/run to load\n",
    "run_number = 'run_00012'\n",
    "\n",
    "## Find the paths to the param_config and model checkpoint\n",
    "# RESULT_DIR = os.path.dirname(REINFORCE_experiment.save_path)    # Can run this after running one experiment\n",
    "BASE_DIR = os.getcwd()\n",
    "RESULT_DIR = os.path.join(BASE_DIR,'cartpole_REINFORCE_results')\n",
    "RUN_DIR = os.path.join(RESULT_DIR, run_number)\n",
    "MODEL_PATH = os.path.join(RUN_DIR,'q_network_checkpoint.pth')\n",
    "\n",
    "## Find the model configuration\n",
    "with open(os.path.join(RUN_DIR,\"param_config.json\"),'r') as f:\n",
    "    data = json.load(f)\n",
    "model_id = 'Policy_MLP_' + data['parameters']['model_id']\n",
    "model_config = model_registry[model_id]['config']\n",
    "\n",
    "# Create a visual simulation of the network\n",
    "RENDER_MODE = \"human\"\n",
    "env_test_visual = gym.make(\"CartPole-v1\",render_mode=RENDER_MODE)\n",
    "obs_space = env_test_visual.observation_space.shape[0]\n",
    "act_space = env_test_visual.action_space.n\n",
    "num_test = 1\n",
    "\n",
    "# Create the model according to the model version in the model registry\n",
    "policy_net_loaded = PolicyNet(obs_space, act_space, model_config)\n",
    "load_model(policy_net_loaded, MODEL_PATH)\n",
    "\n",
    "for episode in range(num_test):\n",
    "    obs, _ = env_test_visual.reset()\n",
    "    done = False\n",
    "    eps_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if CUDA_ENABLED else 'cpu')\n",
    "        action_probs = policy_net_loaded(obs_tensor)\n",
    "        action_dist = Categorical(action_probs)\n",
    "        action = action_dist.sample()\n",
    "        next_obs, reward, term, trunc, _ = env_test_visual.step(action.item())\n",
    "\n",
    "        done = term or trunc\n",
    "        eps_reward += reward\n",
    "        obs = next_obs\n",
    "    \n",
    "    print(f\"Reward from episode {episode:3d} is {eps_reward}\")\n",
    "\n",
    "env_test_visual.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc35fdd",
   "metadata": {},
   "source": [
    "# Actor Critic Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym             # To create the inverted pendulum environment\n",
    "import torch                        \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json                         # to save parameters and results\n",
    "import time                         # to monitor training & validation time\n",
    "from datetime import datetime       # to create a log of runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5498b4b",
   "metadata": {},
   "source": [
    "## Parameter & Class Definition\n",
    "Define the hyperparameters of the experiment(s), the policy network and value network classes, and the REINFORCE experiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e3ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[64,64]):\n",
    "        ''' Initialize the model and create a list of layers '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for layer_size in hidden_layers:\n",
    "            self.layers.append(nn.Linear(input_dim, layer_size))\n",
    "            input_dim = layer_size\n",
    "\n",
    "        self.layers.append(nn.Linear(input_dim, self.output_dim))\n",
    "        if CUDA_ENABLED: self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input = torch.relu(layer(input))\n",
    "        logits = self.layers[-1](input)\n",
    "        probs = torch.softmax(logits,dim=-1)\n",
    "        return probs\n",
    "    \n",
    "class ValueNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers=[32,32]):\n",
    "        ''' Initialize the model and create a list of layers '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        for layer_size in hidden_layers:\n",
    "            self.layers.append(nn.Linear(input_dim, layer_size))\n",
    "            input_dim = layer_size\n",
    "\n",
    "        self.layers.append(nn.Linear(input_dim, self.output_dim))\n",
    "        if CUDA_ENABLED: self.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers[:-1]:\n",
    "            input = torch.relu(layer(input))\n",
    "        output = self.layers[-1](input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29de91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_registry = {\n",
    "    'AC_MLP_v0': {\n",
    "        'class': PolicyNet,\n",
    "        'config': [64,64],\n",
    "        'value_class': ValueNet,\n",
    "        'value_config': [64,64]\n",
    "    },\n",
    "    'AC_MLP_v1': {\n",
    "        'class': PolicyNet,\n",
    "        'config': [128],\n",
    "        'value_class': ValueNet,\n",
    "        'value_config': [128]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c52fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'MODEL': [\"AC_MLP_v0\"],\n",
    "    'ALPHA' : [5e-5, 1e-4, 5e-4, 1e-3],\n",
    "    'BETA' : [1e-3],\n",
    "    'GAMMA': [0.98],\n",
    "    'N_EPISODE_TRAIN': [5000]\n",
    "}\n",
    "\n",
    "N_EPISODE_TEST = 5\n",
    "CUDA_ENABLED = False\n",
    "SUCCESS_CRITERIA = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3a9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic():\n",
    "    def __init__(self, model_name: str,\n",
    "                 model_registry,\n",
    "                 alpha: float,          # learning rate of the policy net\n",
    "                 beta: float,           # learning rate of the state value net\n",
    "                 gamma: float,          # discount rate in RL\n",
    "                 n_episode_train,\n",
    "                 result_folder = 'cartpole_AC_results',\n",
    "                 seed = 42,\n",
    "                 cuda_enabled = False,\n",
    "                 verbose = True):\n",
    "        \n",
    "        self.N_EPISODE_TRAIN = n_episode_train\n",
    "        self.result_folder = result_folder\n",
    "        self.SEED = seed\n",
    "        self.CUDA_ENABLED = cuda_enabled\n",
    "        self.VERBOSE = verbose\n",
    "        self.LOG_PERIOD = 50\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # Initialize the train and validation environments\n",
    "        self.env = gym.make(\"CartPole-v1\")\n",
    "        self.env_val = gym.make(\"CartPole-v1\")\n",
    "        self.obs_space = self.env.observation_space.shape[0]\n",
    "        self.act_space = self.env.action_space.n\n",
    "        \n",
    "        ''' Experiment hyperparameters '''\n",
    "        # Policy model configuration\n",
    "        self.model_name = model_name\n",
    "        match = re.search(r'v\\d+', self.model_name)\n",
    "        self.model_id = match.group(0) if match else 404\n",
    "\n",
    "        self.policy_model_class = model_registry[self.model_name]['class']\n",
    "        self.policy_model_config = model_registry[self.model_name]['config']\n",
    "        self.value_model_class = model_registry[self.model_name]['value_class']\n",
    "        self.value_model_config = model_registry[self.model_name]['value_config']\n",
    "\n",
    "        # Instantiate and initialize the policy network\n",
    "        self.policy_net = self.policy_model_class(self.obs_space, self.act_space, self.policy_model_config)\n",
    "        self.policy_net.apply(self.init_weights)\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr = self.alpha)\n",
    "        \n",
    "        # Instantiate and initialize the state value network\n",
    "        self.value_net = self.value_model_class(self.obs_space, 1, self.value_model_config)\n",
    "        self.value_net.apply(self.init_weights)\n",
    "        self.value_optimizer = optim.Adam(self.value_net.parameters(), lr = self.beta)\n",
    "\n",
    "        self.save_path = ''\n",
    "        self.model_path = ''\n",
    "        self.hyperparam_config = ''\n",
    "        self.reward_history = []\n",
    "        self.val_history = {}                                           # Monitor which episode had a validation run, the train reward, and the validation (test) reward \n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def create_directory(self):\n",
    "        ''' Function that creates directory to save model state_dict, architecture, training configuration, and history\n",
    "\n",
    "        Parameters: \n",
    "        ------------\n",
    "        (hyperparameters for differentiating between different directory)\n",
    "        \n",
    "        lr : float\n",
    "            the learning rate to optimize the Q network\n",
    "        gamma : float \n",
    "            the discount rate in Q learning\n",
    "        \n",
    "        Returns\n",
    "        ------------\n",
    "        name_codified : str\n",
    "            the shortened name for the current experiment \n",
    "        hyperparameters_codified : str\n",
    "            the shortened string of hyperparameter configuration\n",
    "        OUTPUT_DIR : path\n",
    "            the directory to which the training results and model (state_dict and architecture) will be saved\n",
    "        '''\n",
    "        timestamp = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "        BASE_DIR = os.getcwd()\n",
    "        RESULT_DIR = os.path.join(BASE_DIR, \"cartpole_reuslts\", self.result_folder)\n",
    "        os.makedirs(RESULT_DIR, exist_ok=True)      # Create the directory if one does not already exist\n",
    "\n",
    "        # Find the trial # of the latest run\n",
    "        existing_runs = [d for d in os.listdir(RESULT_DIR) if os.path.isdir(os.path.join(RESULT_DIR,d))]\n",
    "        run_numbers = [int(re.search(r'run_(\\d{5})',d).group(1)) for d in existing_runs if re.match(r'run_\\d{5}',d)]\n",
    "        trial_number = max(run_numbers,default=-1)+1\n",
    "\n",
    "        # Create a folder for the run\n",
    "        name_codified = f\"run_{trial_number:05d}\"\n",
    "        OUTPUT_DIR = os.path.join(RESULT_DIR,name_codified)\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)      # Create the directory\n",
    "\n",
    "        # Append the mapping from run # to hyperparameter configuration in a JSON file inside RESULT_DIR\n",
    "        trial_to_param_path = os.path.join(RESULT_DIR,'trial_to_param.json')\n",
    "        if os.path.exists(trial_to_param_path):\n",
    "            with open(trial_to_param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {name_codified: \"\"}\n",
    "\n",
    "        hyperparam_codified = \"AC_\"\n",
    "        hyperparam_codified += \"OOP_\"\n",
    "        hyperparam_codified += \"CUDA_\" if self.CUDA_ENABLED else \"nCUDA_\"\n",
    "        hyperparam_codified += f\"{self.model_id}_{self.alpha}_{self.beta}_{self.gamma}\"\n",
    "        hyperparam_codified_time = f\"{timestamp}_\" + hyperparam_codified\n",
    "\n",
    "        data[name_codified] = hyperparam_codified_time\n",
    "\n",
    "        with open(trial_to_param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Store the training configs in JSON file\n",
    "        training_params = {\n",
    "            'OOP':                  True,\n",
    "            'CUDA':                 self.CUDA_ENABLED,\n",
    "            'device':               torch.cuda.get_device_name(torch.cuda.current_device()),\n",
    "            'model_name':           self.model_name,\n",
    "            'alpha':                self.alpha,\n",
    "            'beta':                 self.beta,\n",
    "            'gamma':                self.gamma,\n",
    "        }\n",
    "\n",
    "        # Store training parameters in each run \n",
    "        param_path = os.path.join(OUTPUT_DIR, \"param_config.json\")\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump({\"parameters\": training_params}, f, indent=2)\n",
    "\n",
    "        return name_codified, hyperparam_codified, OUTPUT_DIR\n",
    "    \n",
    "    def get_returns(self, eps_reward_history):\n",
    "        ''' Function to calculate the return of each time step when given a list of rewards \n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        rewards : list\n",
    "            a list of rewards achieved throughout the agent's trajectory\n",
    "        gamma   : float\n",
    "            the discount factor\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        returns : list\n",
    "            a list of returns G_t at each step of the trajectory\n",
    "            \n",
    "        For each step of th trajectory (of length T):\n",
    "        - Extract the rewards from that step onward\n",
    "        - Each step is multiplied by the corresponding gamma ^ index \n",
    "            the first reward received from leaving the state is not discounted\n",
    "            the last reward received from the trajectory is discouned by gamma ^ (T-1)\n",
    "        - Sum these values together to obtain the return at each step\n",
    "        '''\n",
    "        returns = np.zeros(len(eps_reward_history))\n",
    "        gamma = self.gamma\n",
    "        \n",
    "        for step, _ in enumerate(eps_reward_history):          # step through the \"trajectory\" or history of reward\n",
    "            step_reward = eps_reward_history[step:]            # reward from the current step onward\n",
    "\n",
    "            # List of discounted rewards at each time step\n",
    "            return_val = [gamma ** i * step_reward[i] for i in range(len(step_reward))]\n",
    "            return_val = sum(return_val)\n",
    "            \n",
    "            returns[step] = return_val\n",
    "        return returns\n",
    "\n",
    "    def policy_eval(self, env: gym.Env, n_episode_test = 500, verbose = True):\n",
    "        ''' Assess the average reward when following the policy net in a test environment with random state initialization\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        env : gymnasium environment\n",
    "            this environment can be either the self.env_test or self.env_val environment (whether they are the same)\n",
    "        n_episode_test : int \n",
    "            the number of evaluation episodes\n",
    "        verbose : bool\n",
    "            whether to print testing information \n",
    "\n",
    "        Return:\n",
    "        ----------\n",
    "        average_reward : float\n",
    "            the average reward received from running the test\n",
    "        '''\n",
    "\n",
    "        reward_history = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(n_episode_test):\n",
    "                obs,_ = env.reset()\n",
    "                done = False\n",
    "                eps_reward = 0\n",
    "\n",
    "                while not done:                 # Step thorugh the episode deterministically (no exploration)\n",
    "                    obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "                    action_probs = self.policy_net(obs_tensor)\n",
    "                    action_dist = Categorical(action_probs)\n",
    "                    action = action_dist.sample()\n",
    "                    next_obs, reward, term, trunc, _ = env.step(action.item())\n",
    "\n",
    "                    # Strategy 1 - Accumulate the reward from the environment\n",
    "                    eps_reward += reward\n",
    "\n",
    "                    # TODO - Strategy 2 - evaluate the strategy based on states\n",
    "\n",
    "                    obs = next_obs\n",
    "                    done = term or trunc\n",
    "            \n",
    "                reward_history.append(eps_reward)\n",
    "                if verbose:\n",
    "                    print(f\"Validation episode {i+1:3d}/{n_episode_test}  |   Reward = {eps_reward:4.0f}\",end=\"\\r\")\n",
    "        reward_mean = mean(reward_history)\n",
    "        reward_stdev = stdev(reward_history)\n",
    "        \n",
    "        return reward_mean, reward_stdev\n",
    "    \n",
    "    def EMA_filter(self, reward: list, alpha):\n",
    "        ''' Function that runs an exponential moving average filter along a datastream '''\n",
    "        output = np.zeros(len(reward)+1)\n",
    "        output[0] = reward[0]\n",
    "        for idx, item in enumerate(reward):\n",
    "            output[idx+1] = (1 - alpha) * output[idx] + alpha * item\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def plot_reward_hist(self, alpha = 0.1):\n",
    "        ''' Function that plots the reward and filtered reward per episode, then saves the plot in a specified save directory'''\n",
    "        n_episodes= len(self.reward_history)\n",
    "        episodes = range(n_episodes)\n",
    "        filtered_reward_hist = self.EMA_filter(self.reward_history, alpha)\n",
    "        fig, axes = plt.subplots(2,1, figsize=(20,12))\n",
    "        axes[0].plot(episodes, self.reward_history[:n_episodes], label = 'Total reward', color = \"blue\")\n",
    "        axes[0].plot(episodes, filtered_reward_hist[:n_episodes], label = 'Filtered reward', color = \"red\")\n",
    "        axes[0].set_title(f'Total reward per episode - {self.hyperparam_config}')\n",
    "        axes[0].set_xlabel('Episode')\n",
    "        axes[0].set_ylabel('Reward')\n",
    "        axes[0].legend()\n",
    "\n",
    "        n_episodes= len(self.value_history)\n",
    "        episodes = range(n_episodes)\n",
    "        axes[1].plot(episodes, self.value_history[:n_episodes], label = \"v(s_0)\", color = \"blue\")\n",
    "        # If using baseline with a value estimation model, plot this as well\n",
    "        axes[1].plot(episodes, self.value_est_history[:n_episodes], label = r\"$\\hat v$(s_0)\", color = \"red\")\n",
    "        axes[1].set_title(f'Return in state s_0 - {self.hyperparam_config}')\n",
    "        axes[1].set_xlabel('Episode')\n",
    "        axes[1].set_ylabel('v(s_0)')\n",
    "        axes[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if self.save_path:\n",
    "            plt.savefig(os.path.join(self.save_path,'reward_history.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self):\n",
    "        ''' Function to save the model and optimizer state_dict for inference or continued training '''\n",
    "        self.model_path = os.path.join(self.save_path, 'q_network_checkpoint.pth')\n",
    "        torch.save({\n",
    "            'model_state_dict': self.policy_net.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, self.model_path)\n",
    "\n",
    "    def load_model(self):\n",
    "        ''' This code overwrite the Q_net with the parameters store in the instance's save_path '''\n",
    "        checkpoint = torch.load(self.model_path)\n",
    "        self.policy_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    def train_policy(self):\n",
    "        msg = \"Training ended with no good model found :<\"\n",
    "\n",
    "        # Create the directory to store results\n",
    "        self.run_number, self.hyperparam_config, self.save_path = self.create_directory()\n",
    "\n",
    "        # Training information\n",
    "        title = f\"Actor Critic   |   Model {self.model_name}, alpha={self.alpha}, beta={self.beta}, gamma={self.gamma}\" \n",
    "        if self.VERBOSE: print(title)\n",
    "\n",
    "        self.reward_history = []                # Track the total reward per episode\n",
    "        self.val_history = {}                   # Reset the validation history\n",
    "        self.value_history = []                 # History of the v(s_0) calculated using G_t throughout training\n",
    "        self.value_est_history = []             # History of the \\hat v(s_0) calculated using the value net (baseline case)\n",
    "        self.val_time = 0                       # Time used for validation (s)\n",
    "        episode = 0\n",
    "\n",
    "        # Control of early stopping\n",
    "        consecutive_pass_count = 0\n",
    "        CONSECUTIVE_PASS_LIMIT = 3\n",
    "        EPISODE_REWARD_LIMIT = SUCCESS_CRITERIA\n",
    "        best_reward = 0\n",
    "        self.best_model_episode = None\n",
    "        performance_crit = False                # Whether desired performance is met consistently\n",
    "        train_terminated = False\n",
    "        \n",
    "\n",
    "        self.train_time_start = time.time()\n",
    "        while not train_terminated:             # Experiment level - loop through episodes\n",
    "            obs, _ = self.env.reset(seed=self.SEED)\n",
    "            obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "            obs_init_tensor = obs_tensor\n",
    "            done = False\n",
    "            step = 0\n",
    "            eps_reward_history = []\n",
    "\n",
    "            while not done:                     # Episode level - loop through steps in an episode\n",
    "                action_probs = self.policy_net(obs_tensor)\n",
    "                action_dist = Categorical(action_probs)\n",
    "                action = action_dist.sample()\n",
    "\n",
    "                next_obs, reward, term, trunc, _ = self.env.step(action.item())\n",
    "                done = term or trunc\n",
    "                current_state_value = self.value_net(obs_tensor)\n",
    "                next_obs_tensor = torch.tensor(next_obs, dtype = torch.float32, device = 'cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "                with torch.no_grad():\n",
    "                    if done: target_state_value = torch.tensor([reward], dtype=torch.float32, device='cuda' if self.CUDA_ENABLED else 'cpu')\n",
    "                    else: target_state_value = reward + self.gamma * self.value_net(next_obs_tensor)\n",
    "                delta = target_state_value - current_state_value\n",
    "                \n",
    "                # Find and optimize the value loss\n",
    "                value_loss = nn.MSELoss()(current_state_value, target_state_value)\n",
    "                # value_loss = delta.pow(2)\n",
    "                self.value_optimizer.zero_grad()\n",
    "                value_loss.backward()\n",
    "                self.value_optimizer.step()\n",
    "                \n",
    "                # Find and optimize the policy loss\n",
    "                policy_loss = - delta.detach() * action_dist.log_prob(action)\n",
    "                self.optimizer.zero_grad()\n",
    "                policy_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                eps_reward_history.append(reward)\n",
    "                obs_tensor = next_obs_tensor\n",
    "                \n",
    "                step += 1\n",
    "                \n",
    "            # print(step)\n",
    "            # print(f\"\\nFinal value loss: {value_loss} \\nFinal policy loss: {policy_loss}\")\n",
    "            ## Post episode calculations\n",
    "            # Calculating return state s_0\n",
    "            returns = self.get_returns(eps_reward_history)\n",
    "            self.value_history.append(returns[0])\n",
    "\n",
    "            eps_reward = sum(eps_reward_history)\n",
    "            self.reward_history.append(eps_reward)     # Total reward of episode\n",
    "            \n",
    "            with torch.no_grad():   # Estimate and store \\hat v(s_0)\n",
    "                self.value_est_history.append(self.value_net(obs_init_tensor).item())\n",
    "            \n",
    "            # Periodic data logger\n",
    "            \n",
    "            if episode % self.LOG_PERIOD == 0 and self.VERBOSE:\n",
    "                printout_msg = f\"Episode {episode:5d}/{self.N_EPISODE_TRAIN}: Total reward = {eps_reward:5.1f}   |   G_0 = {returns[0]: 5.2f}   |   $\\hat v(s_0)$ = {self.value_est_history[-1]:6.2f}\" \n",
    "                print(printout_msg, end='\\r')\n",
    "\n",
    "            # Early stopping condition\n",
    "            if eps_reward >= EPISODE_REWARD_LIMIT:\n",
    "                # Evaluate the current good policy and record the validation time\n",
    "                self.val_time_start = time.time()\n",
    "                test_reward, _ = self.policy_eval(self.env_val, 20, verbose=False)\n",
    "                self.val_time += time.time() - self.val_time_start\n",
    "\n",
    "                self.val_history[episode] = [eps_reward, test_reward]\n",
    "\n",
    "                if test_reward >= best_reward:           # Set the new best reward\n",
    "                    best_reward = test_reward\n",
    "                    self.save_model()\n",
    "                    self.best_model_episode = episode\n",
    "                    msg = f\"Training terminated due to episode limit, best model saved at episode {self.best_model_episode:5d}\"\n",
    "                if test_reward > EPISODE_REWARD_LIMIT: \n",
    "                    consecutive_pass_count += 1\n",
    "                else: consecutive_pass_count = 0\n",
    "            else:\n",
    "                consecutive_pass_count = 0\n",
    "\n",
    "            # Performance criteria - if good results for several episodes => training performance satisfied and terminate early\n",
    "            if consecutive_pass_count >= CONSECUTIVE_PASS_LIMIT:\n",
    "                self.save_model()\n",
    "                self.best_model_episode = episode\n",
    "                performance_crit = True \n",
    "                msg = f\"Early termination at episode {self.best_model_episode:5d}, desired performance reached\"\n",
    "\n",
    "\n",
    "            episode += 1\n",
    "\n",
    "            # Checking for early training termination or truncation\n",
    "            train_terminated = (episode >= self.N_EPISODE_TRAIN) or (performance_crit)\n",
    "\n",
    "        self.train_time = time.time() - self.train_time_start\n",
    "\n",
    "        print(f\"\\nTotal runtime - {self.train_time:5.2f}\")\n",
    "        print(msg)\n",
    "        return\n",
    "\n",
    "    def record(self):\n",
    "        # Load the best policy net parameter from the experiment\n",
    "        if self.model_path:\n",
    "            self.load_model()\n",
    "\n",
    "        # Average test reward of the resulting policy - if best policy does not exists use the last one\n",
    "        self.env_test = gym.make('CartPole-v1')\n",
    "        print('Testing the best policy network performance')\n",
    "        reward_mean, reward_stdev = self.policy_eval(self.env_test, n_episode_test=500, verbose=True)\n",
    "        print(f\"\\nValidation average reward {reward_mean:4.2f} (SD = {reward_stdev:4.2f})\")\n",
    "\n",
    "        # Store the validation history and average test reward in the param_config JSON file\n",
    "        param_path = os.path.join(self.save_path, 'param_config.json')\n",
    "        if os.path.exists(param_path):\n",
    "            with open(param_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        else:\n",
    "            data = {}\n",
    "\n",
    "        data['runtime'] = self.train_time\n",
    "        data['valtime'] = self.val_time\n",
    "        data['best_model_at'] = self.best_model_episode\n",
    "        data['val_history'] = self.val_history\n",
    "        data['test_result'] = [reward_mean, reward_stdev]\n",
    "\n",
    "        with open(param_path, \"w\") as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "\n",
    "        # Plot\n",
    "        self.plot_reward_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cf1dd3",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ece2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "keys, values = zip(*param_grid.items())\n",
    "num_config = len(list(itertools.product(*values)))\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed); torch.manual_seed(seed)\n",
    "\n",
    "for idx, v in enumerate(itertools.product(*values)):\n",
    "    for i in range(10):\n",
    "        # Unpack the hyperparameters configurations\n",
    "        config = dict(zip(keys,v))\n",
    "        MODEL_NAME = config['MODEL']\n",
    "        MODEL_CLASS = model_registry[MODEL_NAME]['class']\n",
    "        MODEL_CONFIG = model_registry[MODEL_NAME]['config']\n",
    "        match = re.search(r'v\\d+',MODEL_NAME)\n",
    "        MODEL_ID = match.group(0) if match else 404\n",
    "\n",
    "        ALPHA = config['ALPHA']\n",
    "        BETA = config['BETA']\n",
    "        GAMMA = config['GAMMA']\n",
    "        N_EPISODE_TRAIN = config['N_EPISODE_TRAIN']\n",
    "        \n",
    "        AC_experiment = ActorCritic(MODEL_NAME, \n",
    "                                        model_registry,\n",
    "                                        alpha = ALPHA,\n",
    "                                        beta = BETA,\n",
    "                                        gamma = GAMMA,\n",
    "                                        n_episode_train = N_EPISODE_TRAIN,\n",
    "                                        seed=42,\n",
    "                                        cuda_enabled=CUDA_ENABLED,\n",
    "                                        verbose=True)\n",
    "        AC_experiment.train_policy()\n",
    "        AC_experiment.record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e712e",
   "metadata": {},
   "source": [
    "## Load and Simulate a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(q_network: nn.Module, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    q_network.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64929b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually select a folder/run to load\n",
    "run_number = 'run_00043'\n",
    "\n",
    "## Find the paths to the param_config and model checkpoint\n",
    "# RESULT_DIR = os.path.dirname(REINFORCE_experiment.save_path)    # Can run this after running one experiment\n",
    "BASE_DIR = os.getcwd()\n",
    "RESULT_DIR = os.path.join(BASE_DIR,'cartpole_AC_results')\n",
    "RUN_DIR = os.path.join(RESULT_DIR, run_number)\n",
    "MODEL_PATH = os.path.join(RUN_DIR,'q_network_checkpoint.pth')\n",
    "\n",
    "## Find the model configuration\n",
    "with open(os.path.join(RUN_DIR,\"param_config.json\"),'r') as f:\n",
    "    data = json.load(f)\n",
    "model_name = data['parameters']['model_name']\n",
    "model_config = model_registry[model_name]['config']\n",
    "\n",
    "# Create a visual simulation of the network\n",
    "RENDER_MODE = \"human\"\n",
    "env_test_visual = gym.make(\"CartPole-v1\",render_mode=RENDER_MODE)\n",
    "obs_space = env_test_visual.observation_space.shape[0]\n",
    "act_space = env_test_visual.action_space.n\n",
    "num_test = 1\n",
    "\n",
    "# Create the model according to the model version in the model registry\n",
    "policy_net_loaded = PolicyNet(obs_space, act_space, model_config)\n",
    "load_model(policy_net_loaded, MODEL_PATH)\n",
    "\n",
    "for episode in range(num_test):\n",
    "    obs, _ = env_test_visual.reset()\n",
    "    done = False\n",
    "    eps_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        obs_tensor = torch.tensor(obs, dtype = torch.float32, device = 'cuda' if CUDA_ENABLED else 'cpu')\n",
    "        action_probs = policy_net_loaded(obs_tensor)\n",
    "        action_dist = Categorical(action_probs)\n",
    "        action = action_dist.sample()\n",
    "        next_obs, reward, term, trunc, _ = env_test_visual.step(action.item())\n",
    "\n",
    "        done = term or trunc\n",
    "        eps_reward += reward\n",
    "        obs = next_obs\n",
    "    \n",
    "    print(f\"Reward from episode {episode:3d} is {eps_reward}\")\n",
    "\n",
    "env_test_visual.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
